# routers/inference.py
import os
import re
import sys

import joblib
import numpy as np
import pandas as pd
import torch
import yaml
from lime.lime_tabular import LimeTabularExplainer
from model.models import StudentNet

BASE_DIR = os.path.dirname(os.path.dirname(__file__))  # backend/
MODEL_DIR = os.path.join(BASE_DIR, "model")
DATA_DIR = os.path.join(BASE_DIR, "data")
CKPT_DIR = os.path.join(BASE_DIR, "checkpoints")

sys.path.append(BASE_DIR)

# ------------------------------------------------------------
# Load global probability distribution for percentile
# ------------------------------------------------------------
ALL_PROBS_PATH = os.path.join(DATA_DIR, "all_probs.npy")

if os.path.exists(ALL_PROBS_PATH):
    ALL_PROBS = np.load(ALL_PROBS_PATH).reshape(-1)
    print(f"[INF] Loaded all_probs.npy: {ALL_PROBS.shape}")
else:
    ALL_PROBS = None
    print("[WARN] all_probs.npy not found. Percentile disabled.")


# ------------------------------------------------------------
# UX-friendly probability smoothing (Ï§ëÍ∞ÑÎåÄ ÎàåÎü¨Î≤ÑÎ¶¨Îäî Î∞©Ïãù)
# ------------------------------------------------------------
def adjust_probability(p):
    """
    UX-friendly smoothing.
    0~0.3: Îçî ÎÇÆÏ∂îÍ∏∞
    0.3~0.7: Ï§ëÍ∞ÑÎåÄ ÏïïÏ∂ï
    0.7~1.0: Îçî ÎÜíÏó¨ Í∞ïÏ°∞
    """
    if p < 0.3:
        return p * 0.8
    elif p < 0.7:
        return 0.3 + (p - 0.3) * 0.4
    else:
        return min(1.0, 0.7 + (p - 0.7) * 1.3)


# ------------------------------------------------------------
# Percentile Í≥ÑÏÇ∞
# ------------------------------------------------------------
def compute_percentile(prob):
    if ALL_PROBS is None or len(ALL_PROBS) == 0:
        return None

    rank = np.sum(ALL_PROBS < prob)
    percentile = 100 - int((rank / len(ALL_PROBS)) * 100)

    return percentile


# ------------------------------------------------------------
# 1. Load scaler
# ------------------------------------------------------------
SCALER_PATH = os.path.join(MODEL_DIR, "scaler_age_income.pkl")
SCALER = joblib.load(SCALER_PATH)
print("[INF] Loaded scaler:", SCALER_PATH)


# ------------------------------------------------------------
# 2. Load config.yaml
# ------------------------------------------------------------
CONFIG_PATH = os.path.join(MODEL_DIR, "config.yaml")
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    CONFIG = yaml.safe_load(f)

STU_CFG = CONFIG["student_model"]
TASK_CFG = CONFIG["task"]


# ------------------------------------------------------------
# 3. Initialize StudentNet
# ------------------------------------------------------------
DIM_A = 16
DIM_Y = TASK_CFG["dim_y"]
NUM_CLASSES = TASK_CFG["num_classes"]

DEVICE = "cpu"

student = StudentNet(
    dim_A=DIM_A,
    dim_y=DIM_Y,
    num_classes=NUM_CLASSES,
    z_dim=STU_CFG["z_dim"],
    enc_hidden=STU_CFG["enc_hidden"],
    clf_hidden=STU_CFG["clf_hidden"],
    p_drop=STU_CFG["p_drop"],
    use_layernorm=STU_CFG["use_layernorm"]
).to(DEVICE)
student.eval()

# ------------------------------------------------------------
# 4. Load checkpoint
# ------------------------------------------------------------
CKPT_PATH = os.path.join(CKPT_DIR, CONFIG["student_train"]["ckpt_name"])
state_dict = torch.load(CKPT_PATH, map_location=DEVICE)
student.load_state_dict(state_dict)
print("[INF] StudentNet loaded:", CKPT_PATH)


# ------------------------------------------------------------
# 5. Define predict_proba (for LIME)
# ------------------------------------------------------------
def student_predict_proba(X_numpy):
    X_tensor = torch.tensor(X_numpy, dtype=torch.float32).to(DEVICE)
    with torch.no_grad():
        y_logits, _, _ = student(X_tensor)
        probs = torch.softmax(y_logits, dim=-1).cpu().numpy()
    return probs


# ------------------------------------------------------------
# 6. Load A.csv ‚Üí LIME background
# ------------------------------------------------------------
FEATURE_NAMES = [
    "Ïó∞Î†π", "Í∞ÄÏ°± Íµ¨ÏÑ±Ïõê Ïàò", "Ï£ºÌÉùÍ∑úÎ™®", "ÏõîÌèâÍ∑† Í∞ÄÍµ¨ÏÜåÎìù",
    "ÏÑ±Î≥Ñ_1", "ÏÑ±Î≥Ñ_2",
    "Ï£ºÌÉùÌòïÌÉú_1", "Ï£ºÌÉùÌòïÌÉú_2", "Ï£ºÌÉùÌòïÌÉú_3", "Ï£ºÌÉùÌòïÌÉú_4",
    "Ìñ•ÌõÑ Î∞òÎ†§ÎèôÎ¨º ÏÇ¨Ïú°ÏùòÌñ•",
    "ÌôîÏù¥Ìä∏ÏπºÎùº", "Î∏îÎ£®ÏπºÎùº", "ÏûêÏòÅÏóÖ", "ÎπÑÍ≤ΩÏ†úÌôúÎèôÏ∏µ", "Í∏∞ÌÉÄ"
]

scale_cols = ["Ïó∞Î†π", "Í∞ÄÏ°± Íµ¨ÏÑ±Ïõê Ïàò", "Ï£ºÌÉùÍ∑úÎ™®", "ÏõîÌèâÍ∑† Í∞ÄÍµ¨ÏÜåÎìù"]

df_A = pd.read_csv(os.path.join(DATA_DIR, "A.csv"))
df_A_scaled = df_A.copy()
df_A_scaled[scale_cols] = SCALER.transform(df_A[scale_cols])

background = df_A_scaled.values[:200]  # only 200 samples
print(f"[INF] LIME background loaded: {background.shape}")


# ------------------------------------------------------------
# 7. LIME Explainer
# ------------------------------------------------------------
lime_explainer = LimeTabularExplainer(
    training_data=background,
    feature_names=FEATURE_NAMES,
    class_names=["0", "1"],
    mode="classification",
    discretize_continuous=True
)


# ------------------------------------------------------------
# 8. LIME ‚Üí clean feature name + mapping
# ------------------------------------------------------------
def clean_feature_name(raw):
    tokens = raw.split()
    for t in tokens:
        if re.match(r'^[Í∞Ä-Ìû£A-Za-z_]', t):
            return t.strip()
    return raw.strip()


HUMAN_MAP = {
    "Ïó∞Î†π": "Ïó∞Î†π",
    "Í∞ÄÏ°± Íµ¨ÏÑ±Ïõê Ïàò": "Í∞ÄÏ°± Íµ¨ÏÑ±Ïõê Ïàò",
    "Ï£ºÌÉùÍ∑úÎ™®": "Ï£ºÌÉù Í∑úÎ™®",
    "ÏõîÌèâÍ∑† Í∞ÄÍµ¨ÏÜåÎìù": "ÏõîÌèâÍ∑† Í∞ÄÍµ¨ÏÜåÎìù",
    "Ìñ•ÌõÑ Î∞òÎ†§ÎèôÎ¨º ÏÇ¨Ïú°ÏùòÌñ•": "ÏÇ¨Ïú° ÏùòÌñ•",

    "ÏÑ±Î≥Ñ_1": "ÎÇ®ÏÑ±",
    "ÏÑ±Î≥Ñ_2": "Ïó¨ÏÑ±",

    "Ï£ºÌÉùÌòïÌÉú_1": "ÏïÑÌååÌä∏",
    "Ï£ºÌÉùÌòïÌÉú_2": "Îã®ÎèÖ/Îã§Í∞ÄÍµ¨",
    "Ï£ºÌÉùÌòïÌÉú_3": "Ïó∞Î¶Ω/ÎπåÎùº/Îã§ÏÑ∏ÎåÄ",
    "Ï£ºÌÉùÌòïÌÉú_4": "Í∏∞ÌÉÄ Ï£ºÍ±∞ÌòïÌÉú",

    "ÌôîÏù¥Ìä∏ÏπºÎùº": "ÌôîÏù¥Ìä∏ÏπºÎùº",
    "Î∏îÎ£®ÏπºÎùº": "Î∏îÎ£®ÏπºÎùº",
    "ÏûêÏòÅÏóÖ": "ÏûêÏòÅÏóÖ",
    "ÎπÑÍ≤ΩÏ†úÌôúÎèôÏ∏µ": "ÎπÑÍ≤ΩÏ†úÌôúÎèôÏ∏µ",
    "Í∏∞ÌÉÄ": "Í∏∞ÌÉÄ ÏßÅÏóÖÍµ∞",
}

def human_name(n):
    return HUMAN_MAP.get(n, n)


def infer_lime(df_scaled):
    x = df_scaled.values[0]
    explanation = lime_explainer.explain_instance(
        data_row=x,
        predict_fn=student_predict_proba,
        num_features=16
    )

    raw_list = explanation.as_list()
    result = {}

    for raw_key, weight in raw_list:
        clean = clean_feature_name(raw_key)
        pretty = human_name(clean)
        result[pretty] = float(weight)

    sorted_items = sorted(result.items(), key=lambda x: abs(x[1]), reverse=True)
    return dict(sorted_items)


# ------------------------------------------------------------
# 9. Main inference
# ------------------------------------------------------------
def infer_student(features: dict):

    A_COLUMNS = [
        "Ïó∞Î†π", "Í∞ÄÏ°± Íµ¨ÏÑ±Ïõê Ïàò", "Ï£ºÌÉùÍ∑úÎ™®", "ÏõîÌèâÍ∑† Í∞ÄÍµ¨ÏÜåÎìù",
        "ÏÑ±Î≥Ñ_1", "ÏÑ±Î≥Ñ_2",
        "Ï£ºÌÉùÌòïÌÉú_1", "Ï£ºÌÉùÌòïÌÉú_2", "Ï£ºÌÉùÌòïÌÉú_3", "Ï£ºÌÉùÌòïÌÉú_4",
        "Ìñ•ÌõÑ Î∞òÎ†§ÎèôÎ¨º ÏÇ¨Ïú°ÏùòÌñ•",
        "ÌôîÏù¥Ìä∏ÏπºÎùº", "Î∏îÎ£®ÏπºÎùº", "ÏûêÏòÅÏóÖ", "ÎπÑÍ≤ΩÏ†úÌôúÎèôÏ∏µ", "Í∏∞ÌÉÄ"
    ]

    df_raw = pd.DataFrame([features])

    df_scaled_part = pd.DataFrame(
        SCALER.transform(df_raw[scale_cols]),
        columns=scale_cols
    )

    df_rest = df_raw[[c for c in A_COLUMNS if c not in scale_cols]]
    df_final = pd.concat([df_scaled_part, df_rest], axis=1)[A_COLUMNS]

    x = torch.tensor(df_final.values, dtype=torch.float32).to(DEVICE)

    with torch.no_grad():
        y_logits, z_a, feats = student(x)

    probs = torch.softmax(y_logits, dim=-1).cpu().numpy()[0]
    prob_raw = float(probs[1])            # Î™®Îç∏ ÏõêÎ≥∏ ÌôïÎ•†
    prob_adj = adjust_probability(prob_raw)  # üî• UX-friendly ÌôïÎ•†

    percentile = compute_percentile(prob_adj)

    return {
        "input_raw": df_raw.to_dict("records")[0],
        "input_scaled": df_final.to_dict("records")[0],
        "latent_vector": z_a.cpu().numpy().tolist()[0],
        "logits": y_logits.cpu().numpy().tolist()[0],
        "probability": prob_adj,       # üî• ÏÇ¨Ïö©Ïûê ÌëúÏãú ÌôïÎ•†
        "percentile": percentile,      
        "features": feats
    }
