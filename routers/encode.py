# routers/encode.py
import asyncio
import os
import traceback
from datetime import datetime

import pandas as pd
from dotenv import load_dotenv
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from pymongo import MongoClient
from routers.inference import infer_lime, infer_student
from utils.gpt_summary_utils import generate_recommendations_text, generate_summary_text
from utils.interaction_utils import compute_interaction_sets

load_dotenv()

router = APIRouter(prefix="/encode", tags=["Encode"])

# --------------------------------------------------------
# MongoDB
# --------------------------------------------------------
MONGO_URI = os.getenv("MONGODB_URI")
client = MongoClient(MONGO_URI)
db = client[os.getenv("REPORT_DB", "pet_rec")]
collection = db["reports"]


# --------------------------------------------------------
# ì €ì¥ ìŠ¤í‚¤ë§ˆ
# --------------------------------------------------------
class ReportData(BaseModel):
    latent_vector: list | dict | None = None
    summary: str | None = None
    recommendations: str | None = None
    raw_input: dict | None = None
    lime: dict | None = None
    logits: list | None = None
    probability: float | None = None
    percentile: int | None = None
    interaction: list | None = None
    timestamp: str | None = None


# --------------------------------------------------------
# ì˜ì–´â†’í•œê¸€
# --------------------------------------------------------
FIELD_MAP = {
    "age": "ì—°ë ¹",
    "familyCount": "ê°€ì¡± êµ¬ì„±ì› ìˆ˜",
    "houseSize": "ì£¼íƒê·œëª¨",
    "budget": "ì›”í‰ê·  ê°€êµ¬ì†Œë“",

    "sex1": "ì„±ë³„_1",
    "sex2": "ì„±ë³„_2",

    "residenceType1": "ì£¼íƒí˜•íƒœ_1",
    "residenceType2": "ì£¼íƒí˜•íƒœ_2",
    "residenceType3": "ì£¼íƒí˜•íƒœ_3",
    "residenceType4": "ì£¼íƒí˜•íƒœ_4",

    "wantingPet": "í–¥í›„ ë°˜ë ¤ë™ë¬¼ ì‚¬ìœ¡ì˜í–¥",

    "job1": "í™”ì´íŠ¸ì¹¼ë¼",
    "job2": "ë¸”ë£¨ì¹¼ë¼",
    "job7": "ìì˜ì—…",
    "job8": "ë¹„ê²½ì œí™œë™ì¸µ",
    "job10": "ê¸°íƒ€",
}

def convert_to_korean_keys(A: dict) -> dict:
    converted = {}
    for eng, val in A.items():
        if eng in FIELD_MAP:
            key = FIELD_MAP[eng]
            try:
                val = float(val)
            except:
                pass
            converted[key] = val
    return converted


# --------------------------------------------------------
# Interaction Feature Groups
# --------------------------------------------------------
FEATURE_GROUPS = {
    "ì—°ë ¹": ["ì—°ë ¹"],
    "ê°€ì¡±": ["ê°€ì¡± êµ¬ì„±ì› ìˆ˜"],
    "ì£¼íƒê·œëª¨": ["ì£¼íƒê·œëª¨"],
    "ì†Œë“": ["ì›”í‰ê·  ê°€êµ¬ì†Œë“"],

    "ì„±ë³„": ["ì„±ë³„_1", "ì„±ë³„_2"],
    "ì£¼íƒí˜•íƒœ": ["ì£¼íƒí˜•íƒœ_1","ì£¼íƒí˜•íƒœ_2","ì£¼íƒí˜•íƒœ_3","ì£¼íƒí˜•íƒœ_4"],
    "ì§ì—…": ["í™”ì´íŠ¸ì¹¼ë¼","ë¸”ë£¨ì¹¼ë¼","ìì˜ì—…","ë¹„ê²½ì œí™œë™ì¸µ","ê¸°íƒ€"],
}


async def save_report(user_id: str, report: ReportData):
    collection.update_one(
        {"userId": user_id},
        {"$set": {"userId": user_id, "report": report.dict()}},
        upsert=True
    )


# --------------------------------------------------------
# POST /encode/{user_id}
# --------------------------------------------------------
@router.post("/{user_id}")
async def encodeA_and_save(user_id: str, features: dict):

    print("\n===== ğŸ”¥ encode í˜¸ì¶œ =====")
    print("raw features:", features)

    feat_dict = convert_to_korean_keys(features)
    print("converted:", feat_dict)

    # ------------------------------------
    # 1) ëª¨ë¸ ì˜ˆì¸¡
    # ------------------------------------
    try:
        result = infer_student(feat_dict)
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(500, f"infer_student ì‹¤íŒ¨: {e}")

    prob = result["probability"]
    percentile = result.get("percentile", None)

    # ------------------------------------
    # 2) LIME ê³„ì‚°
    # ------------------------------------
    try:
        lime = infer_lime(pd.DataFrame([result["input_scaled"]]))
    except Exception:
        traceback.print_exc()
        raise HTTPException(500, "infer_lime ì‹¤íŒ¨")

    top5 = sorted(lime.items(), key=lambda x: abs(x[1]), reverse=True)[:5]


    # ------------------------------------
    # 3) Interaction ê³„ì‚° (GPTë³´ë‹¤ ë¨¼ì €)
    # ------------------------------------
    def f_local(d):
        return infer_student(d)["probability"]

    try:
        interaction_top3 = compute_interaction_sets(
            result["input_raw"],
            f_local,
            FEATURE_GROUPS,
            top_k=3
        )
    except Exception:
        traceback.print_exc()
        interaction_top3 = None

    print("INTERACTIONS:", interaction_top3)


    # ------------------------------------
    # 4) GPT ìš”ì•½/ì¶”ì²œ (interaction í¬í•¨)
    # ------------------------------------
    clean_input = {
        k: v for k, v in result["input_raw"].items()
        if not (str(v) == "0" or v == 0)
    }

    try:
        summary_task = generate_summary_text(prob, top5, interaction_top3, clean_input)
        rec_task = generate_recommendations_text(prob, top5, interaction_top3, clean_input)
        summary, recommendations = await asyncio.gather(summary_task, rec_task)
    except Exception:
        traceback.print_exc()
        summary = None
        recommendations = None


    # ------------------------------------
    # 5) ReportData êµ¬ì„±
    # ------------------------------------
    report = ReportData(
        raw_input=result["input_raw"],
        latent_vector=result["latent_vector"],
        logits=result["logits"],
        probability=prob,
        percentile=percentile,
        lime=lime,
        summary=summary,
        recommendations=recommendations,
        interaction=interaction_top3,
        timestamp=datetime.utcnow().isoformat(),
    )

    await save_report(user_id, report)

    return {
        "success": True,
        "data": report.dict()
    }
