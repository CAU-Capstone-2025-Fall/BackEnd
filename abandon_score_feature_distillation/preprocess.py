import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

df = pd.read_excel("data/survey.xlsx", sheet_name="ë§ˆì´í¬ë¡œë°ì´í„°", header=[0,1])
df.columns = df.columns.get_level_values(1)

# 1) í•„í„°ë§ (ì‚¬ìœ¡ê²½í—˜ì + ìœ ê¸°ì¶©ë™ ì‘ë‹µì)
df["A1"] = pd.to_numeric(df["A1"], errors="coerce")
df["B3"] = pd.to_numeric(df["B3"], errors="coerce")
mask = df["A1"].isin([1,2]) & df["B3"].notna()
df_target = df[mask].copy()

print("ğŸ¾ ì‚¬ìœ¡ê²½í—˜ì:", df["A1"].isin([1,2]).sum())
print("ğŸ“Œ ìœ ê¸°ì¶©ë™ ì‘ë‹µì:", mask.sum())

# 2) A4 ë¬¸ìì—´ í´ë¦°ì§• + ìˆ«ì ë³€í™˜
def clean_num(x):
    if pd.isna(x):
        return np.nan
    return str(x).strip().replace("\n", "").replace("\t", "").replace(" ", "")

df_target["A4_clean"] = df_target["A4"].apply(clean_num)
df_target["A4_num"] = pd.to_numeric(df_target["A4_clean"], errors="coerce")

print("\nğŸ”¥ A4 ì›ë³¸ â†’ ìˆ«ì ë³€í™˜ unique:")
print(df_target["A4_num"].unique())

# 3) ê°’ ì¶”ì¶œ
vals = df_target["A4_num"].values.reshape(-1,1)

# 4) -1~1 ì •ê·œí™”
if len(np.unique(vals)) == 1:
    print("âš  ê°’ì´ ëª¨ë‘ ë™ì¼ â†’ 0ìœ¼ë¡œ ì €ì¥")
    norm_vals = np.zeros(len(vals))
else:
    scaler = MinMaxScaler(feature_range=(-1, 1))
    norm_vals = scaler.fit_transform(vals).flatten()
print(df["A4"].value_counts(dropna=False))
print(df.loc[df["A1"].isin([1,2]) & df["B3"].notna(), ["A1","B3","A4"]].head(20))

# 5) ì €ì¥
out = pd.DataFrame({"í–¥í›„ ë°˜ë ¤ë™ë¬¼ ì‚¬ìœ¡ì˜í–¥_norm": norm_vals})
out.to_csv("data/A4_labeled_norm.csv", index=False, encoding="utf-8-sig")
print(df.columns.tolist())

print("\nğŸ¯ ì™„ë£Œ â€” ì €ì¥ë¨: data/A4_labeled_norm.csv")
