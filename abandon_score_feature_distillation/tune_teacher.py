import copy
import json
import os
import shutil
from pathlib import Path

import numpy as np
import optuna
import torch
import torch.nn as nn
import yaml

# â—ï¸[ìˆ˜ì •] ìƒˆ models, train_utilsë¥¼ import
from dataio import load_inputs_and_labels
from models import TeacherNet
from train_utils import make_loaders, metrics_dict, resolve_device

# ------------------------------------------------------------
# 0. ê¸°ë³¸ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent
CONFIG_PATH = BASE_DIR / "config.yaml"

with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    CFG = yaml.safe_load(f)

DEVICE = resolve_device(CFG['common_train']['device'])
# â—ï¸ ì „ì—­ ì‹œë“œëŠ” ì—¬ê¸°ì„œ í•œ ë²ˆ ê³ ì • (ë°ì´í„° ë¶„í•  ë“±)
torch.manual_seed(CFG['common_train']['seed'])

A, B, Y = load_inputs_and_labels(CFG)
dim_A, dim_B = A.shape[1], B.shape[1]
dim_y, num_classes = CFG['task']['dim_y'], CFG['task']['num_classes']

# â—ï¸ í›ˆë ¨/ê²€ì¦ ë¡œë”ë¥¼ ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ ìƒì„± (ëª¨ë“  íŠ¸ë¼ì´ì–¼ì´ ê³µìœ )
train_loader, val_loader = make_loaders(A, B, Y, CFG)

print(f"[INFO] Data loaded. Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}")
print(f"[INFO] Using device: {DEVICE}")
print(f"[INFO] Target Metric: Accuracy")
print(f"[INFO] â—ï¸ Tuner Seed Fix: ACTIVATED (Seed={CFG['common_train']['seed']})")
print(f"[INFO] â—ï¸ Class Weighting: ACTIVATED (SQUARED - 'ìª¼ê¸ˆ ë”' ì¤Œ)")

# ------------------------------------------------------------
# 2. Optuna Objective ì •ì˜ (Teacher í›ˆë ¨ + Accuracy ë°˜í™˜)
# ------------------------------------------------------------
def objective(trial):
    """
    TeacherNetì˜ 'Validation Accuracy'ë¥¼ ìµœëŒ€í™”í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    
    # â—ï¸ [í•µì‹¬] ì¬í˜„ì„±ì„ ìœ„í•´ ëª¨ë“  íŠ¸ë¼ì´ì–¼ì˜ ëœë¤ ì‹œë“œ ê³ ì •
    torch.manual_seed(CFG['common_train']['seed'])
    
    # --- 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì œì•ˆ ---
    lr = trial.suggest_loguniform("lr", 1e-4, 3e-3) 
    weight_decay = trial.suggest_loguniform("weight_decay", 1e-5, 1e-3)
    p_drop = trial.suggest_float("p_drop", 0.1, 0.4)
    
    z_dim = trial.suggest_categorical("z_dim", [32, 64, 128]) 
    
    enc_hidden_str = trial.suggest_categorical("enc_hidden", [
        "(128,)", "(256,)", "(128, 64)", "(256, 128)", "(256, 128, 64)" 
    ])
    enc_hidden = eval(enc_hidden_str)

    clf_hidden_str = trial.suggest_categorical("clf_hidden", [
        "(128,)", "(256,)", "(128, 64)", "(256, 128)", "(256, 128, 64)"
    ])
    clf_hidden = eval(clf_hidden_str)

    use_layernorm = trial.suggest_categorical("use_layernorm", [True, False])

    # --- 2. ì„¤ì • êµ¬ì„± ---
    model_cfg = {
        "dim_A": dim_A, "dim_B": dim_B, "dim_y": dim_y, "num_classes": num_classes,
        "z_dim_A": z_dim, "z_dim_B": z_dim,
        "encA_hidden": enc_hidden,
        "encB_hidden": enc_hidden,
        "clf_hidden": clf_hidden,
        "p_drop": p_drop,
        "use_layernorm": use_layernorm, 
    }
    
    train_cfg = CFG['common_train'].copy()
    train_cfg.update(CFG['teacher_train']) 
    train_cfg.update({
        "device": DEVICE,
        "lr": lr,
        "weight_decay": weight_decay,
        "ckpt_dir": os.path.join(BASE_DIR, "tune_ckpt_teacher") # ì„ì‹œ ì €ì¥
    })

    # --- 3. í›ˆë ¨ ì‹¤í–‰ ---
    model = TeacherNet(**model_cfg).to(DEVICE)
    opt = torch.optim.AdamW(model.parameters(), lr=train_cfg['lr'], weight_decay=train_cfg['weight_decay'])
    
    # â—ï¸ [í•µì‹¬ ìˆ˜ì •] Class Weighting "ìª¼ê¸ˆ ë”" (ì œê³±) ì ìš©
    train_indices = train_loader.dataset.indices
    y_tensor_full = torch.tensor(Y, dtype=torch.long) 
    y_train_tensor = y_tensor_full[train_indices]
    class_counts = torch.bincount(y_train_tensor, minlength=num_classes).float()
    
    weights = (class_counts / class_counts.sum())
    
    # â—ï¸ [ìˆ˜ì •] "ìª¼ê¸ˆ ë”" ì£¼ê¸° -> ê°€ì¤‘ì¹˜ë¥¼ ì œê³±í•˜ì—¬ í¸í–¥ì„ ê°•í™”
    weights = torch.pow(weights, 2)
    # (ì¬ì •ê·œí™”)
    weights = (weights / weights.sum()).to(DEVICE)

    criterion = nn.CrossEntropyLoss(weight=weights)
    
    best_val_score = 0.0
    best_state = None
    patience_counter = 0

    try:
        for epoch in range(1, train_cfg['epochs'] + 1):
            model.train()
            for a_batch, b_batch, y_batch in train_loader:
                a_batch, b_batch, y_batch = a_batch.to(DEVICE), b_batch.to(DEVICE), y_batch.to(DEVICE)
                opt.zero_grad()
                
                y_pred_logits, _, _ = model(a_batch, b_batch)
                
                loss = criterion(y_pred_logits.view(-1, num_classes), y_batch.view(-1))
                loss.backward()
                opt.step()

            # ---- Validation (ë§¤ ì—í¬í¬ë§ˆë‹¤ Acc ê³„ì‚°) ----
            model.eval()
            y_true_all, y_pred_all = [], []
            with torch.no_grad():
                for a_batch, b_batch, y_batch in val_loader:
                    a_batch, b_batch, y_batch = a_batch.to(DEVICE), b_batch.to(DEVICE), y_batch.to(DEVICE)
                    yp_logits, _, _ = model(a_batch, b_batch)
                    
                    yp_classes = yp_logits.view(-1, dim_y, num_classes).argmax(dim=2)
                    y_true_all.append(y_batch)
                    y_pred_all.append(yp_classes)
            
            va_metrics = metrics_dict(torch.cat(y_true_all), torch.cat(y_pred_all))
            current_val_score = va_metrics.get('Accuracy', 0.0) 
            
            if current_val_score > best_val_score:
                best_val_score = current_val_score
                best_state = copy.deepcopy(model.state_dict())
                patience_counter = 0
            else:
                patience_counter += 1
                if patience_counter >= train_cfg['early_stop_patience']:
                    break 

        return best_val_score

    except Exception as e:
        print(f"âš ï¸ Trial {trial.number} failed: {e}")
        import traceback
        traceback.print_exc()
        return 0.0 

# ------------------------------------------------------------
# 3. Optuna ì‹¤í–‰
# ------------------------------------------------------------
# â—ï¸ [ìˆ˜ì •] "ìª¼ê¸ˆ ë”" ë²„ì „ì„ ìœ„í•œ ìƒˆ ì´ë¦„
STUDY_NAME = "teacher_tune_weighted_pow2_v1" 
STORAGE = f"sqlite:///{os.path.join(BASE_DIR, 'optuna_teacher.db')}"
N_TRIALS = 150 

shutil.rmtree(os.path.join(BASE_DIR, "tune_ckpt_teacher"), ignore_errors=True)
os.makedirs(os.path.join(BASE_DIR, "tune_ckpt_teacher"), exist_ok=True)

study = optuna.create_study(
    direction="maximize", 
    study_name=STUDY_NAME,
    storage=STORAGE,
    load_if_exists=True,
)
print(f"Starting Optuna study: {STUDY_NAME} [Storage: {STORAGE}]")
study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True) 

# ------------------------------------------------------------
# 4. ê²°ê³¼ ì €ì¥
# ------------------------------------------------------------
print("\n" + "="*30)
print(f"===== ğŸ§  Best Teacher Trial ({STUDY_NAME}) =====")
best = study.best_trial
print(f"  Value (Max Val Accuracy): {best.value:.6f}")
print("  Params: ")
for k, v in best.params.items():
    print(f"    {k}: {v}")

os.makedirs(os.path.join(BASE_DIR, "tune_logs"), exist_ok=True)
# â—ï¸ [ìˆ˜ì •] ìƒˆ json íŒŒì¼ ì´ë¦„
best_params_path = os.path.join(BASE_DIR, "tune_logs", "best_teacher_params_weighted_pow2.json") 
with open(best_params_path, "w", encoding="utf-8") as f:
    json.dump(
        {
            "best_params": best.params,
            "best_value(Accuracy)": best.value,
        },
        f,
        indent=2,
        ensure_ascii=False,
    )

print(f"\n[DONE] ìµœì  Teacher íŒŒë¼ë¯¸í„° ì €ì¥ ì™„ë£Œ â†’ {best_params_path}")
print("ì´ì œ ì´ íŒŒë¼ë¯¸í„°ë¥¼ config.yamlì— ë°˜ì˜í•˜ê³  [run_distill.py]ë¥¼ ì‹¤í–‰í•˜ì—¬ 'teacher.pt'ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
print("ê·¸ ë‹¤ìŒ, [run_optuna_student.py]ë¥¼ ì‹¤í–‰í•˜ì—¬ í•™ìƒì„ íŠœë‹í•˜ì„¸ìš”.")

if __name__ == "__main__":
    pass