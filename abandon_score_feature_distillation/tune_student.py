# tuner_optuna.py
# (â—ï¸ [í•µì‹¬ ìˆ˜ì •] ì¬í˜„ì„± ë³´ì¥ + lr/wd íŠœë‹ + ë¹¡ì„¼ íƒìƒ‰)

import os
from pathlib import Path

import optuna
import torch
import yaml

# â—ï¸[ìˆ˜ì •] ìƒˆ models, trainer, train_utilsì—ì„œ import
from dataio import load_inputs_and_labels
from models import StudentNet, TeacherNet
from train_utils import make_loaders, metrics_dict
from trainer import train_student_distill


# -------------------------------------------------------------
# Teacher ë¡œë“œ
# -------------------------------------------------------------
def load_teacher(cfg, dim_A, dim_B, device):
    teacher_model_cfg = cfg["teacher_model"].copy()
    teacher_model_cfg.update({
        "dim_A": dim_A, "dim_B": dim_B,
        "dim_y": cfg["task"]["dim_y"], "num_classes": cfg["task"]["num_classes"]
    })

    ckpt_path = Path(cfg["paths"]["ckpt_dir"]) / cfg["teacher_train"]["ckpt_name"]
    if not ckpt_path.exists():
        print(f"ğŸ”¥ ERROR: Teacher checkpoint not found at {ckpt_path}")
        print("ë¨¼ì € 'run_distill.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ 85.15%ì§œë¦¬ teacher.ptë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        raise FileNotFoundError(ckpt_path)
        
    teacher = TeacherNet(**teacher_model_cfg).to(device)
    state = torch.load(ckpt_path, map_location=device, weights_only=True)
    teacher.load_state_dict(state)

    teacher.eval()
    for p in teacher.parameters():
        p.requires_grad_(False)

    # â—ï¸ [ìˆ˜ì •] ìš”ì²­í•˜ì‹  ëŒ€ë¡œ 85.15% ë¡œë“œ ë©”ì‹œì§€ ì œê±°
    # print(f"[INFO] Teacher (85.15%) loaded â†’ {ckpt_path}") 
    return teacher, teacher_model_cfg


# -------------------------------------------------------------
# Student í‰ê°€ (3-value ë°˜í™˜ ì²˜ë¦¬)
# -------------------------------------------------------------
def evaluate_student(student, val_loader, device, num_classes=2, dim_y=1):
    student.eval()
    y_true_list, y_pred_list = [], []

    with torch.no_grad():
        for a_batch, b_batch, y_batch in val_loader:
            a_batch = a_batch.to(device)
            y_batch = y_batch.to(device)
            logits, _, _ = student(a_batch) # 3-value
            preds = logits.view(-1, dim_y, num_classes).argmax(dim=2)
            y_true_list.append(y_batch)
            y_pred_list.append(preds)

    y_true = torch.cat(y_true_list)
    y_pred = torch.cat(y_pred_list)
    return metrics_dict(y_true, y_pred)


# -------------------------------------------------------------
# Optuna Objective (â—ï¸ [í•µì‹¬ ìˆ˜ì •] ë¹¡ì„¸ê²Œ íŠœë‹ + ì‹œë“œ ê³ ì •)
# -------------------------------------------------------------
def objective(trial):

    base = Path(__file__).resolve().parent
    cfg = yaml.safe_load(open(base / "config.yaml", "r", encoding="utf-8"))

    # â—ï¸ [í•„ìˆ˜] ì¬í˜„ì„±ì„ ìœ„í•´ ëª¨ë“  íŠ¸ë¼ì´ì–¼ì˜ ì‹œë“œë¥¼ ê³ ì •!
    torch.manual_seed(cfg['common_train']['seed'])

    device = "cuda" if torch.cuda.is_available() else "cpu"

    A, B, Y = load_inputs_and_labels(cfg)
    train_loader, val_loader = make_loaders(A, B, Y, cfg)

    dim_A, dim_B = A.shape[1], B.shape[1]
    num_classes = cfg["task"]["num_classes"]
    dim_y = cfg["task"]["dim_y"]

    teacher, teacher_model_cfg = load_teacher(cfg, dim_A, dim_B, device)

    # --- 1. STUDENT STRUCTURE ---
    
    # â—ï¸ [ê³ ì •] z_dim, enc_hiddenì€ Feature KDë¥¼ ìœ„í•´ Teacherì™€ ë™ì¼í•´ì•¼ í•¨
    z_dim = teacher_model_cfg["z_dim_A"]
    enc_hidden = tuple(teacher_model_cfg["encA_hidden"])

    # â—ï¸ [ë¹¡ì„¼ íŠœë‹] Studentì˜ Classifierë§Œ íŠœë‹
    clf_hidden_str = trial.suggest_categorical("clf_hidden", [
        "(64,)", "(128,)", "(256,)", "(512,)",
        "(128, 64)", "(256, 128)", "(512, 256)",
        "(256, 128, 64)", "(512, 256, 128)"
    ])
    clf_hidden = eval(clf_hidden_str)

    # â—ï¸ [ë¹¡ì„¼ íŠœë‹] p_drop ë²”ìœ„ í™•ì¥
    p_drop = trial.suggest_float("p_drop", 0.05, 0.5)
    use_layernorm = trial.suggest_categorical("use_layernorm", [False, True])

    student_model_cfg = {
        "dim_A": dim_A, "dim_y": dim_y, "num_classes": num_classes,
        "z_dim": z_dim,
        "enc_hidden": enc_hidden,
        "clf_hidden": clf_hidden,
        "p_drop": p_drop,
        "use_layernorm": use_layernorm,
    }

    # --- 2. â—ï¸ [ë¹¡ì„¼ íŠœë‹] OPTIMIZER & KD PARAMS ---
    
    # â—ï¸ [ì¶”ê°€] Studentì˜ lr/wdë„ íŠœë‹
    lr = trial.suggest_float("lr", 1e-5, 5e-3, log=True)
    weight_decay = trial.suggest_float("weight_decay", 1e-6, 1e-2, log=True)
    
    # â—ï¸ [ë¹¡ì„¼ íŠœë‹] KD íŒŒë¼ë¯¸í„° ë²”ìœ„ í™•ì¥
    alpha = trial.suggest_float("alpha", 0.05, 0.95) 
    beta_z = trial.suggest_float("beta_z", 0.1, 5.0, log=True) 
    temperature = trial.suggest_float("temperature", 1.5, 10.0)
    gamma_feat = trial.suggest_float("gamma_feat", 0.1, 20.0, log=True) 

    kd_cfg = {
        "alpha": alpha,
        "temperature": temperature,
        "beta_z": beta_z,
        "gamma_feat": gamma_feat
    }

    # --- 3. TRAIN STUDENT ---
    ckpt_dir = str(base / "tune_ckpt_student")
    # os.makedirs(ckpt_dir, exist_ok=True) # (íŒŒì¼ ìƒë‹¨ì—ì„œ ì´ë¯¸ ìƒì„±í•¨)
    
    train_cfg = {
        **cfg["common_train"],
        # â—ï¸ [ìˆ˜ì •] íŠœë‹ëœ lr/wd ì‚¬ìš©
        "lr": lr,
        "weight_decay": weight_decay,
        
        "device": device,
        "ckpt_dir": ckpt_dir,
        "ckpt_name": f"student_trial_{trial.number}.pt",
    }
    try:
        student = train_student_distill(
            A, B, Y,
            teacher=teacher,
            train_loader=train_loader,
            val_loader=val_loader,
            model_cfg=student_model_cfg,
            train_cfg=train_cfg,
            kd_cfg=kd_cfg,
            StudentNet=StudentNet,
        )

        # --- 4. EVAL ---
        metrics = evaluate_student(student, val_loader, device, num_classes, dim_y)
        score = metrics.get("Accuracy", 0) 

        # â—ï¸ [ì¶”ê°€] ìš”ì²­í•˜ì‹  ëŒ€ë¡œ ë§¤ íŠ¸ë¼ì´ì–¼ ì¢…ë£Œ ì‹œ Accuracy ì¶œë ¥
        print(f"--- Trial {trial.number} FINISHED --- Score (Accuracy): {score:.6f}")

        return score

    except Exception as e:
        print(f"ğŸ”¥ TRIAL FAILED! Exact Error:")
        import traceback
        traceback.print_exc()
        return -1e9

# -------------------------------------------------------------
# RUN OPTUNA
# -------------------------------------------------------------
def run_optuna(n_trials=200): # â—ï¸ 150 -> 200íšŒ "ë¹¡ì„¸ê²Œ"
    storage_name = "sqlite:///optuna_feature_kd.db"
    
    # â—ï¸[ìˆ˜ì •] lr/wd íŠœë‹ì„ í¬í•¨í•˜ëŠ” ìƒˆ Study ì´ë¦„
    study_name = "student_tune_full_vs_85_teacher_v5" # v2 -> v3
    
    study = optuna.create_study(
        study_name=study_name,
        storage=storage_name,
        load_if_exists=True,
        direction="maximize"
    )
    
    print(f"Starting Optuna Student (Full Tune vs 85% Teacher, Seed Fixed) study: {study_name}")
    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

    print(f"\nğŸ”¥ Best Params ({study_name})")
    print(study.best_params)
    print("\nğŸ”¥ Best Score (Accuracy)", study.best_value)

    return study


if __name__ == "__main__":
    # â—ï¸(85.15% 'teacher.pt'ê°€ checkpoints í´ë”ì— ìˆëŠ”ì§€ í™•ì¸!)
    run_optuna(200) # â—ï¸ 200íšŒ