import copy
import json
import os
import shutil
from pathlib import Path

import numpy as np
import optuna
import torch
import torch.nn as nn
import yaml
from dataio import load_inputs_and_labels
from models import TeacherNet
from train_utils import make_loaders, metrics_dict, resolve_device

# ------------------------------------------------------------
# 0. ê¸°ë³¸ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent
CONFIG_PATH = BASE_DIR / "config.yaml"

with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    CFG = yaml.safe_load(f)

DEVICE = resolve_device(CFG['common_train']['device'])
torch.manual_seed(CFG['common_train']['seed'])

A, B, Y = load_inputs_and_labels(CFG)
dim_A, dim_B = A.shape[1], B.shape[1]
dim_y, num_classes = CFG['task']['dim_y'], CFG['task']['num_classes']

# â—ï¸ í›ˆë ¨/ê²€ì¦ ë¡œë”ë¥¼ ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ ìƒì„±
train_loader, val_loader = make_loaders(A, B, Y, CFG)

print(f"[INFO] Data loaded. Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}")
print(f"[INFO] Using device: {DEVICE}")
print(f"[INFO] Target Metric: Accuracy") # ğŸ‘ˆ [ìˆ˜ì •]

# ------------------------------------------------------------
# 2. Optuna Objective ì •ì˜ (Teacher í›ˆë ¨ + Accuracy ë°˜í™˜)
# ------------------------------------------------------------
def objective(trial):
    """
    TeacherNetì˜ 'Validation Accuracy'ë¥¼ ìµœëŒ€í™”í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    
    # --- 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì œì•ˆ ---
    
    # Training
    lr = trial.suggest_loguniform("lr", 1e-4, 3e-3) 
    weight_decay = trial.suggest_loguniform("weight_decay", 1e-5, 1e-3)
    p_drop = trial.suggest_float("p_drop", 0.1, 0.4)
    
    # Structure
    z_dim = trial.suggest_categorical("z_dim", [32, 64, 128]) 
    
    enc_hidden_str = trial.suggest_categorical("enc_hidden", [
        "(128,)", 
        "(256,)", 
        "(128, 64)", 
        "(256, 128)",
        "(256, 128, 64)" 
    ])
    enc_hidden = eval(enc_hidden_str)

    clf_hidden_str = trial.suggest_categorical("clf_hidden", [
        "(128,)", 
        "(256,)", 
        "(128, 64)", 
        "(256, 128)",
        "(256, 128, 64)"
    ])
    clf_hidden = eval(clf_hidden_str)

    use_layernorm = trial.suggest_categorical("use_layernorm", [True, False])

    # --- 2. ì„¤ì • êµ¬ì„± ---
    model_cfg = {
        "dim_A": dim_A, "dim_B": dim_B, "dim_y": dim_y, "num_classes": num_classes,
        "z_dim_A": z_dim, "z_dim_B": z_dim,
        "encA_hidden": enc_hidden,
        "encB_hidden": enc_hidden,
        "clf_hidden": clf_hidden,
        "p_drop": p_drop,
        "use_layernorm": use_layernorm, 
    }
    
    train_cfg = CFG['common_train'].copy()
    train_cfg.update(CFG['teacher_train']) 
    train_cfg.update({
        "device": DEVICE,
        "lr": lr,
        "weight_decay": weight_decay,
        "ckpt_dir": os.path.join(BASE_DIR, "tune_ckpt_teacher")
    })

    # --- 3. í›ˆë ¨ ì‹¤í–‰ ---
    model = TeacherNet(**model_cfg).to(DEVICE)
    opt = torch.optim.AdamW(model.parameters(), lr=train_cfg['lr'], weight_decay=train_cfg['weight_decay'])
    criterion = nn.CrossEntropyLoss()
    
    best_val_score = 0.0 # ğŸ‘ˆ [ìˆ˜ì •] Accuracy ê¸°ì¤€
    best_state = None
    patience_counter = 0

    try:
        for epoch in range(1, train_cfg['epochs'] + 1):
            model.train()
            for a_batch, b_batch, y_batch in train_loader:
                a_batch, b_batch, y_batch = a_batch.to(DEVICE), b_batch.to(DEVICE), y_batch.to(DEVICE)
                opt.zero_grad()
                y_pred_logits, _, _ = model(a_batch, b_batch)
                loss = criterion(y_pred_logits.view(-1, num_classes), y_batch.view(-1))
                loss.backward()
                opt.step()

            # ---- Validation (ë§¤ ì—í¬í¬ë§ˆë‹¤ Acc ê³„ì‚°) ----
            model.eval()
            y_true_all, y_pred_all = [], []
            with torch.no_grad():
                for a_batch, b_batch, y_batch in val_loader:
                    a_batch, b_batch, y_batch = a_batch.to(DEVICE), b_batch.to(DEVICE), y_batch.to(DEVICE)
                    yp_logits, _, _ = model(a_batch, b_batch)
                    
                    yp_classes = yp_logits.view(-1, dim_y, num_classes).argmax(dim=2)
                    y_true_all.append(y_batch)
                    y_pred_all.append(yp_classes)
            
            va_metrics = metrics_dict(torch.cat(y_true_all), torch.cat(y_pred_all))
            
            # ğŸ‘ˆ [ìˆ˜ì •] Accuracyë¥¼ ëª©í‘œ ì ìˆ˜ë¡œ ì‚¬ìš©
            current_val_score = va_metrics.get('Accuracy', 0.0) 
            
            # ğŸ‘ˆ [ìˆ˜ì •] ìµœê³  "Accuracy"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ ì €ì¥
            if current_val_score > best_val_score:
                best_val_score = current_val_score
                best_state = copy.deepcopy(model.state_dict())
                patience_counter = 0
            else:
                patience_counter += 1
                if patience_counter >= train_cfg['early_stop_patience']:
                    break 

        # ğŸ‘ˆ [ìˆ˜ì •] ìµœê³  "Accuracy"ë¥¼ Optunaì— ë°˜í™˜
        return best_val_score

    except Exception as e:
        print(f"âš ï¸ Trial {trial.number} failed: {e}")
        import traceback
        traceback.print_exc()
        return 0.0 

# ------------------------------------------------------------
# 3. Optuna ì‹¤í–‰
# ------------------------------------------------------------
# ğŸ‘ˆ [ìˆ˜ì •] ìŠ¤í„°ë”” ì´ë¦„ ë³€ê²½ (Accuracy ëª…ì‹œ)
STUDY_NAME = "teacher_full_structure_tune_acc_v1" 
STORAGE = f"sqlite:///{os.path.join(BASE_DIR, 'optuna_teacher.db')}"
N_TRIALS = 100  

shutil.rmtree(os.path.join(BASE_DIR, "tune_ckpt_teacher"), ignore_errors=True)
os.makedirs(os.path.join(BASE_DIR, "tune_ckpt_teacher"), exist_ok=True)

study = optuna.create_study(
    direction="maximize", # "Accuracy"ë¥¼ "ìµœëŒ€í™”"
    study_name=STUDY_NAME,
    storage=STORAGE,
    load_if_exists=True,
)
print(f"Starting Optuna study: {STUDY_NAME} [Storage: {STORAGE}]")
study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True) 

# ------------------------------------------------------------
# 4. ê²°ê³¼ ì €ì¥
# ------------------------------------------------------------
print("\n" + "="*30)
print("===== ğŸ§  Best Teacher Trial (Accuracy) =====") # ğŸ‘ˆ [ìˆ˜ì •]
best = study.best_trial
print(f"  Value (Max Val Accuracy): {best.value:.6f}") # ğŸ‘ˆ [ìˆ˜ì •]
print("  Params: ")
for k, v in best.params.items():
    print(f"    {k}: {v}")

os.makedirs(os.path.join(BASE_DIR, "tune_logs"), exist_ok=True)
# ğŸ‘ˆ [ìˆ˜ì •] íŒŒì¼ ì´ë¦„ ë³€ê²½ (acc ëª…ì‹œ)
best_params_path = os.path.join(BASE_DIR, "tune_logs", "best_teacher_params_acc.json") 
with open(best_params_path, "w", encoding="utf-8") as f:
    json.dump(
        {
            "best_params": best.params,
            "best_value(Accuracy)": best.value, # ğŸ‘ˆ [ìˆ˜ì •]
        },
        f,
        indent=2,
        ensure_ascii=False,
    )

print(f"\n[DONE] ìµœì  Teacher íŒŒë¼ë¯¸í„° ì €ì¥ ì™„ë£Œ â†’ {best_params_path}")
print("ì´ì œ ì´ íŒŒë¼ë¯¸í„°ë¥¼ config.yamlì— ë°˜ì˜í•˜ê³  [run_distill.py]ë¥¼ ì‹¤í–‰í•˜ì—¬ 'teacher.pt'ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
print("ê·¸ ë‹¤ìŒ, [run_optuna_student.py]ë¥¼ ì‹¤í–‰í•˜ì—¬ í•™ìƒì„ íŠœë‹í•˜ì„¸ìš”.")

if __name__ == "__main__":
    pass