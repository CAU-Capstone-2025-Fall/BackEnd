# ============================================================
# ğŸ¶ A_processed ë³µì› â€” 'í–¥í›„ ë°˜ë ¤ë™ë¬¼ ì‚¬ìœ¡ì˜í–¥' (1~5 â†’ 0~1)
# ============================================================

import re

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# 1ï¸âƒ£ ì—‘ì…€ ì›ë³¸ ë¡œë“œ
df = pd.read_excel("survey.xlsx", sheet_name="ë§ˆì´í¬ë¡œë°ì´í„°", header=[0,1])
df.columns = df.columns.get_level_values(1)

# 2ï¸âƒ£ ì»¬ëŸ¼ëª…ì—ì„œ ì¤„ë°”ê¿ˆ ì œê±° í›„ ì¼ì¹˜ íƒìƒ‰
clean_cols = {c: re.sub(r"\s+", "", str(c)) for c in df.columns}
target_col = None
for orig, clean in clean_cols.items():
    if "í–¥í›„ë°˜ë ¤ë™ë¬¼ì‚¬ìœ¡ì˜í–¥" in clean or "A4" in clean:
        target_col = orig
        break

if target_col is None:
    raise ValueError("âš ï¸ 'í–¥í›„ ë°˜ë ¤ë™ë¬¼ ì‚¬ìœ¡ ì˜í–¥' ë¬¸í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

print(f"âœ… ê°ì§€ëœ ì»¬ëŸ¼ëª…: {repr(target_col)}")

# 3ï¸âƒ£ ê°’ ì¶”ì¶œ (1~5 Likert)
A4_values = pd.to_numeric(df[target_col], errors="coerce").fillna(0).values.reshape(-1, 1)
print("ğŸ“Š ì›ë³¸ ë¶„í¬:")
print(pd.Series(A4_values.flatten()).value_counts().sort_index())

# 4ï¸âƒ£ 0~1 ì •ê·œí™”
scaler = MinMaxScaler()
A4_norm = scaler.fit_transform(A4_values)

# 5ï¸âƒ£ A_processed ë¶ˆëŸ¬ì˜¤ê¸° ë° ëŒ€ì²´
A = pd.read_csv("A_processed.csv")
A["í–¥í›„ ë°˜ë ¤ë™ë¬¼ ì‚¬ìœ¡ì˜í–¥"] = A4_norm

# 6ï¸âƒ£ ì €ì¥
output_path = "A_processed_fixed.csv"
A.to_csv(output_path, index=False, encoding="utf-8-sig")

print(f"\nğŸ¯ ì™„ë£Œ â€” ì €ì¥ë¨: {output_path}")
print(A[["í–¥í›„ ë°˜ë ¤ë™ë¬¼ ì‚¬ìœ¡ì˜í–¥"]].describe())
