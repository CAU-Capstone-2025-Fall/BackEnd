import re

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# ===========================================================
# 1ï¸âƒ£ íŒŒì¼ ë¡œë“œ
# ===========================================================
file_path = "survey.xlsx"
df_raw = pd.read_excel(file_path, sheet_name="ë§ˆì´í¬ë¡œë°ì´í„°", header=[0, 1])
df_raw.columns = df_raw.columns.get_level_values(1)
df = df_raw.copy()

# ===========================================================
# 2ï¸âƒ£ DROP (A ì¤‘ë³µ, ê¸°íƒ€ ë“±)
# ===========================================================
drop_cols = [
    "ID", "SQ1", "SQ2", "SQ2_R", "SQ3_2", "SQ3_2_R",
    "DQ1", "DQ2", "DQ2_ETC4", "DQ3", "DQ4", "DQ5"
]
drop_keywords = ["ê¸°íƒ€", "ETC", "OPEN", "ì¼ë ¨ë²ˆí˜¸", "ìì¹˜êµ¬", "ê¶Œì—­"]

df = df.drop(columns=[c for c in df.columns if any(k in str(c) for k in drop_keywords) or c in drop_cols],
             errors="ignore")

# ===========================================================
# 3ï¸âƒ£ ë³µìˆ˜ì‘ë‹µí˜• ë§¤í•‘ ì •ì˜
# ===========================================================
multi_mapping = {
    "A2#": {
        1: "ê´€ë¦¬ë¹„ìš©ë¶€ë‹´",
        2: "ì´ì›ƒê°€ì¡±ê°ˆë“±",
        3: "ì´ìƒí–‰ë™ìœ„ìƒë¬¸ì œ",
        4: "ì‹œê°„ê³µê°„ë¶€ì¡±",
        5: "ì—¬í–‰ì™¸ì¶œê³¤ë€",
        6: "ì£½ìŒìŠ¬í””",
        7: "ê°€ì¶œì‹¤ì¢…",
    },
    "A3#": {
        1: "ê¹¨ë—í•˜ê²Œí‚¤ìš¸ìì‹ ì—†ìŒ",
        2: "ì£¼ê±°í™˜ê²½ë‚˜ì¨",
        3: "ì‚¬ìœ¡ë¹„ìš©ë¶€ë‹´",
        4: "ì‹œê°„ë¶€ì¡±",
        5: "ê³µê°„ì—†ìŒ",
        6: "ë™ë¬¼ì‹«ì–´í•¨",
        7: "ê°€ì¡±ë°˜ëŒ€",
    },
    "A5#": {
        1: "ëƒ„ìƒˆì‹¬í•¨",
        2: "í„¸ë‚ ë¦¼",
        3: "ì†ŒìŒ",
        4: "ëŒ€ì†Œë³€ì˜¤ì—¼",
        5: "ë¬¼ë¦¬ê±°ë‚˜ìœ„í˜‘",
        6: "êµí†µì‚¬ê³ ",
        7: "ê³µì›ì‹ë‹¹ë¶ˆí¸",
        9: "í”¼í•´ì—†ìŒ",
    },
    "B1#": {
        1: "êµìœ¡ê´€ë¦¬",
        2: "ì˜ˆë°©ì¹˜ë£Œ",
        3: "ëª©ìš•ìš´ë™",
        4: "ì¢‹ì€ë¨¹ì´",
        5: "ìŠµì„±êµìœ¡",
        6: "ê³µì¤‘ê·œë²”",
    },
    "B2#": {
        1: "ë¹„ìš©ë¶€ë‹´",
        2: "ê°€ì¡±ê°ˆë“±",
        3: "ìœ„ìƒë¬¸ì œ",
        4: "ì—¬ê±´ê³¤ë€",
        5: "ì—¬í–‰ì–´ë ¤ì›€",
    },
    "A1_2": {
        1: "ì•„ì´ë“¤ì •ì„œêµìœ¡",
        2: "ì˜ˆì˜ê³ ê·€ì—¬ì›Œì„œ",
        3: "ì™¸ë¡œì›Œì„œ",
        4: "ìš°ì—°íˆê¸°íšŒ",
        5: "ìœ ê¸°ê²¬ë¶ˆìŒ",
    },
}

# ===========================================================
# 4ï¸âƒ£ ë¬¸ìì—´ ê¸°ë°˜ ë³µìˆ˜ì‘ë‹µí˜• â†’ 0/1 ë³€í™˜ í•¨ìˆ˜
# ===========================================================
def clean_to_codes(value):
    """'1, 3', '1 3', '1;3' ë“±ì„ [1,3]ìœ¼ë¡œ ë³€í™˜"""
    if pd.isna(value):
        return []
    if isinstance(value, (int, float)):
        return [int(value)]
    tokens = re.split(r"[ ,;/]+", str(value).strip())
    return [int(t) for t in tokens if t.isdigit()]

# ===========================================================
# 5ï¸âƒ£ ë³µìˆ˜ì‘ë‹µí˜• ë³€í™˜ (A2#, A3#, A5#, B1#, B2#, A1_2)
# ===========================================================
df_result = df.copy()

for prefix, mapping in multi_mapping.items():
    target_cols = [c for c in df.columns if c.startswith(prefix.replace("#", ""))]
    if not target_cols:
        continue

    for col in target_cols:
        df_result[col] = df_result[col].apply(clean_to_codes)
        for code, label in mapping.items():
            new_col = f"{prefix.replace('#', '')}_{label}"
            has_code = df_result[col].apply(lambda lst: code in lst)
            if new_col not in df_result.columns:
                df_result[new_col] = has_code.astype(int)
            else:
                df_result[new_col] = df_result[new_col] | has_code.astype(int)

    df_result.drop(columns=target_cols, inplace=True, errors="ignore")

print("âœ… ë³µìˆ˜ì‘ë‹µí˜• ì™„ì „ ë³€í™˜ ì™„ë£Œ (ëª¨ë“  0/1 ì²˜ë¦¬)")

# ===========================================================
# ===========================================================
# ğŸ”¹ A1 (í˜„ì¬/ê³¼ê±°/ë¬´ê²½í—˜) â†’ ì›í•« ì¸ì½”ë”©
# ===========================================================
if "A1" in df_result.columns:
    A1_map = {
        1: "í˜„ì¬_ë°˜ë ¤ë™ë¬¼_ìˆìŒ",
        2: "ê³¼ê±°ì—ëŠ”_ìˆì—ˆìœ¼ë‚˜_ì§€ê¸ˆì€_ì—†ìŒ",
        3: "ë°˜ë ¤ë™ë¬¼_ê²½í—˜_ì—†ìŒ",
    }
    for code, label in A1_map.items():
        df_result[f"A1_{label}"] = (df_result["A1"] == code).astype(int)
    df_result.drop(columns=["A1"], inplace=True, errors="ignore")
print("âœ… A1 ì›í•« ì¸ì½”ë”© ì™„ë£Œ (3ê°œ ì»¬ëŸ¼)")

# ===========================================================
# ğŸ”¹ A4 (1~5 Likert) â†’ 0~1 ì •ê·œí™”
# ===========================================================
if "A4" in df_result.columns:
    df_result["A4"] = pd.to_numeric(df_result["A4"], errors="coerce").fillna(0)
    scaler_A4 = MinMaxScaler(feature_range=(0, 1))
    df_result["A4_norm"] = scaler_A4.fit_transform(df_result[["A4"]])
    df_result.drop(columns=["A4"], inplace=True)
print("âœ… A4 ì •ê·œí™” ì™„ë£Œ (0~1 ìŠ¤ì¼€ì¼)")

# ===========================================================
# ğŸ”¹ C5_1, C5_2, C5_3, C6 (1~10) â†’ ì›í•« ì¸ì½”ë”© (ê¸°íƒ€=9 ì œê±°)
# ===========================================================
C5_labels = {
    1: "ê¸°ë³¸ì†Œì–‘êµìœ¡",
    2: "êµ¬ì¡°ë³´í˜¸",
    3: "ì˜ˆë°©ë°ì¹˜ë£Œ",
    4: "í›ˆë ¨ìŠµì„±í™”",
    5: "ì‚¬ë£Œìš©í’ˆêµ¬ì…",
    6: "ì—¬í–‰ê´€ë¦¬",
    7: "ì†Œë¹„ìí”¼í•´ìƒë‹´",
    8: "ì¥ë¡€ì‹œì„¤",
    10: "í•„ìš”ì‚¬ì—…ì—†ìŒ"
}

for col in ["C5_1", "C5_2", "C5_3", "C6"]:
    if col not in df_result.columns:
        continue
    df_result[col] = pd.to_numeric(df_result[col], errors="coerce")
    for code, label in C5_labels.items():
        if code == 9:  # ê¸°íƒ€ í•­ëª© ì œê±°
            continue
        new_col = f"{col}_{label}"
        df_result[new_col] = (df_result[col] == code).astype(int)
    df_result.drop(columns=[col], inplace=True)

print("âœ… C5/C6 ìˆœìœ„í˜• ë¬¸í•­ ì›í•« ì¸ì½”ë”© ì™„ë£Œ (ê¸°íƒ€ ì œì™¸)")

# ===========================================================
C5_map = {
    1: "ê¸°ë³¸ì†Œì–‘êµìœ¡",
    2: "êµ¬ì¡°ë³´í˜¸",
    3: "ì˜ˆë°©ë°ì¹˜ë£Œ",
    4: "í›ˆë ¨ìŠµì„±í™”",
    5: "ì‚¬ë£Œìš©í’ˆêµ¬ì…",
    6: "ì—¬í–‰ê´€ë¦¬",
    7: "ì†Œë¹„ìí”¼í•´ìƒë‹´",
    8: "ì¥ë¡€ì‹œì„¤",
}

rank_cols = ["C5#1", "C5#2", "C5#3"]
rank_names = ["1ìˆœìœ„", "2ìˆœìœ„", "3ìˆœìœ„"]

for col, rank in zip(rank_cols, rank_names):
    if col not in df_result.columns:
        continue
    df_result[col] = pd.to_numeric(df_result[col], errors="coerce")
    for code, desc in C5_map.items():
        new_col = f"C5_{desc}_{rank}"
        df_result[new_col] = (df_result[col] == code).astype(int)

df_result.drop(columns=rank_cols, inplace=True, errors="ignore")
print("âœ… C5 ìˆœìœ„í˜• ë¬¸í•­ ì›í•« ë³€í™˜ ì™„ë£Œ (1~3ìˆœìœ„, ê¸°íƒ€ ì œì™¸)")

# ===========================================================
# 7ï¸âƒ£ Likert ë¬¸í•­ (0~1 ì •ê·œí™”)
# ===========================================================
likert_cols = [
    "B3", "B4", "C1", "C2",
    "C3_1", "C3_2", "C3_3", "C3_4",
    "C3_5", "C3_6", "C3_7", "C3_8", "C4"
]

likert_rename = {
    "B3": "ë°˜ë ¤ë™ë¬¼ ìœ ê¸° ì¶©ë™ ê²½í—˜",
    "B4": "ìƒˆë¡œìš´ ë°˜ë ¤ë™ë¬¼ ì‚¬ìœ¡ ì˜í–¥",
    "C1": "ë™ë¬¼ë³´í˜¸ì„¼í„° ìš´ì˜ ì¸ì§€ì •ë„",
    "C2": "ì„œìš¸ì‹œì˜ í­ë„“ì€ ë™ë¬¼ë³´í˜¸ì„¼í„° ìš´ì˜ ì°¬ì„±ì •ë„",
    "C3_1": "ì‹œë¯¼ë³µì§€ ê´€ì  ì •ë¶€ ê´€ì‹¬ í•„ìš”",
    "C3_2": "ìì¹˜êµ¬ ê¸°ëŠ¥ë§Œìœ¼ë¡œ ì •ë¶€ ì—­í•  ë¶€ì¡±",
    "C3_3": "ì¤‘ì•™ì •ë¶€ ì„œìš¸ì‹œ ì»¨íŠ¸ë¡¤íƒ€ì›Œ ì—­í•  í•„ìš”",
    "C3_4": "ê³µê³µ ì‚¬ìœ¡ê´€ë¦¬êµìœ¡ ê°ˆë“±ì¡°ì • í•„ìš”",
    "C3_5": "ë¯¼ê°„ë¶€ë¬¸ì´ ë‹´ë‹¹í•˜ê¸° ì–´ë ¤ìš´ ì˜ì—­ ì¡´ì¬",
    "C3_6": "ë³µì§€ì‹œì„¤íˆ¬ìë³´ë‹¤ ì‹œë¯¼ë³µì§€ìš°ì„ ",
    "C3_7": "ë°˜ë ¤ì¸ ì±…ì„ ê°•ì¡° ê³µê³µì—­í•  ìµœì†Œ",
    "C3_8": "ê³µê³µì‚¬ì—…ì‹œ ë¯¼ê°„ë‹¨ì²´ì‹œì„¤ í™œìš©",
    "C4": "ë°˜ë ¤ë™ë¬¼ ê´€ë ¨ ì •ë¶€ ì¤‘ìš” ì—­í•  ì¸ì‹",
}

existing_cols = [c for c in likert_rename if c in df_result.columns]
df_result.rename(columns={k: likert_rename[k] for k in existing_cols}, inplace=True)
likert_cols = [likert_rename[k] for k in existing_cols]

df_result[likert_cols] = df_result[likert_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
scaler = MinMaxScaler()
df_result[likert_cols] = scaler.fit_transform(df_result[likert_cols])

print(f"âœ… Likert ì •ê·œí™” ì™„ë£Œ ({len(likert_cols)}ê°œ ì»¬ëŸ¼)")

# ===========================================================
# 8ï¸âƒ£ ì €ì¥
# ===========================================================
df_result = df_result.fillna(0)
df_result.to_csv("B_processed_final.csv", index=False, encoding="utf-8-sig")

print(f"ğŸ¯ ì €ì¥ ì™„ë£Œ: B_processed_final.csv ({df_result.shape})")
print("ğŸ“˜ ì˜ˆì‹œ ì»¬ëŸ¼:", list(df_result.columns[:15]))
