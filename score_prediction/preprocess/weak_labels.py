# ============================================================
# ğŸ§© Multidimensional Weak Label ìƒì„± (gpt-4o-mini, with QUESTION & SUB_QUESTION mapping)
# ============================================================

import json
import os
import re

import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI
from tqdm import tqdm

# ------------------------------------------------------------
# âœ… í™˜ê²½ ì„¤ì •
# ------------------------------------------------------------
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

DATA_DIR = "../data"
FILE_PATH = os.path.join(DATA_DIR, "survey.xlsx")
OUTPUT_PATH = os.path.join(DATA_DIR, "weak_labels_multidim_v3.csv")
MODEL_NAME = "gpt-4o-mini"  # âœ… ì•ˆì •ì  JSON ì¶œë ¥ ì§€ì› ëª¨ë¸

# ------------------------------------------------------------
# ğŸ§© JSON íŒŒì‹± í•¨ìˆ˜
# ------------------------------------------------------------
def safe_parse_json(text: str):
    """GPT ì¶œë ¥ì—ì„œ JSON ë¸”ë¡ë§Œ ì¶”ì¶œ í›„ íŒŒì‹±"""
    try:
        match = re.search(r"\{[\s\S]*\}", text)
        if match:
            clean_json = match.group(0)
            return json.loads(clean_json)
        else:
            return json.loads(text.strip())
    except Exception as e:
        print("âš ï¸ JSON Parse Error:", e)
        print("ğŸ§© Raw content (first 300 chars):", text[:300])
        return None


# ------------------------------------------------------------
# 1ï¸âƒ£ ì‹œíŠ¸ ë¡œë“œ
# ------------------------------------------------------------
if not os.path.exists(FILE_PATH):
    raise FileNotFoundError(f"âŒ {FILE_PATH} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

df_raw = pd.read_excel(FILE_PATH, sheet_name="ë§ˆì´í¬ë¡œë°ì´í„°", header=[0, 1])
df_raw.columns = df_raw.columns.get_level_values(1)
df_code = pd.read_excel(FILE_PATH, sheet_name="ì½”ë”©")

print(f"[INFO] ë§ˆì´í¬ë¡œë°ì´í„° shape: {df_raw.shape}")
print(f"[INFO] ì½”ë”© ì‹œíŠ¸ shape: {df_code.shape}")

# ------------------------------------------------------------
# 2ï¸âƒ£ ë§¤í•‘ í…Œì´ë¸” ìƒì„± (QUESTION + SUB_QUESTION ìš°ì„ )
# ------------------------------------------------------------
df_code["ANSWER"] = df_code["ANSWER"].astype(str).str.strip()
df_code["VALUE"] = df_code["VALUE"].astype(str).str.strip()
df_code["QUESTION"] = df_code["QUESTION"].astype(str).str.strip()
if "SUB_QUESTION" in df_code.columns:
    df_code["SUB_QUESTION"] = df_code["SUB_QUESTION"].astype(str).str.strip()
else:
    df_code["SUB_QUESTION"] = ""

# (1) VALUE ë§¤í•‘ (COLUMNNAME + ANSWER â†’ VALUE)
code_map = {}
for _, row in df_code.dropna(subset=["COLUMNNAME", "ANSWER", "VALUE"]).iterrows():
    col = str(row["COLUMNNAME"]).strip()
    ans = str(row["ANSWER"]).strip()
    val = str(row["VALUE"]).strip()
    code_map[(col, ans)] = val
    # ìˆ«ìí˜• í—ˆìš© ("2" == "2.0")
    try:
        f_ans = str(float(ans))
        code_map[(col, f_ans)] = val
        i_ans = str(int(float(ans)))
        code_map[(col, i_ans)] = val
    except:
        pass

# (2) QUESTION ë§¤í•‘ (SUB_QUESTION ìš°ì„ , ì—†ìœ¼ë©´ QUESTION)
question_map = {}
for _, row in df_code.dropna(subset=["COLUMNNAME"]).iterrows():
    colname = str(row["COLUMNNAME"]).strip()
    sub_q = str(row.get("SUB_QUESTION", "")).strip()
    main_q = str(row.get("QUESTION", "")).strip()

    if sub_q and sub_q.lower() != "nan":
        question_map[colname] = sub_q
    elif main_q and main_q.lower() != "nan":
        question_map[colname] = main_q

print(f"[INFO] ì½”ë“œ ë§¤í•‘ {len(code_map)}ê°œ, ì§ˆë¬¸ ë§¤í•‘ {len(question_map)}ê°œ ìƒì„± ì™„ë£Œ\n")

# ------------------------------------------------------------
# 3ï¸âƒ£ ì‘ë‹µ ë³µì›
# ------------------------------------------------------------
df_text = pd.DataFrame()

for col in df_raw.columns:
    responses = []
    for _, val in enumerate(df_raw[col]):
        if pd.isna(val):
            responses.append(None)
            continue

        val_str = str(val).strip()
        key = (col, val_str)
        mapped = code_map.get(key)

        # ìˆ«ìí˜• í—ˆìš© (2 == 2.0)
        if mapped is None:
            try:
                val_float = str(float(val))
                mapped = code_map.get((col, val_float))
            except:
                mapped = None

        responses.append(mapped if mapped is not None else None)

    df_text[col] = responses

print(f"âœ… í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ: {df_text.shape[0]}ê°œ ì‘ë‹µ, {df_text.shape[1]}ê°œ ë¬¸í•­")

# ------------------------------------------------------------
# 4ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ë¹Œë” â€” COLUMNNAMEì„ QUESTION/SUB_QUESTION í…ìŠ¤íŠ¸ë¡œ ë§¤í•‘
# ------------------------------------------------------------
def build_prompt(row):
    items = []
    for col, val in row.items():
        if val is None or (isinstance(val, float) and pd.isna(val)):
            continue

        question_text = question_map.get(col, col)
        items.append(f"{question_text}: {val}")

    joined = "\n".join(items)

    prompt = f"""
You are a **strict and critical evaluator** analyzing survey responses about pet ownership.

Below is one respondentâ€™s survey answers.

{joined}

Your task is to **evaluate this respondent conservatively** across six distinct psychological and behavioral dimensions 
related to responsible pet ownership.

Be **objective, analytical, and slightly skeptical**. Avoid giving high scores unless the evidence in the responses 
strongly supports them.

Each dimension must receive an **integer score between 0 and 10**, where:
- 0â€“3 = poor or concerning tendencies
- 4â€“6 = average or mixed tendencies
- 7â€“8 = above average, but not perfect
- 9â€“10 = outstanding and clearly justified tendencies

Dimensions:
1. empathy â€” emotional understanding and compassion toward animals
2. ethicality â€” moral responsibility and respect for animal welfare
3. self_control â€” impulse management and steady caregiving intention
4. care_environment â€” quality of financial, spatial, and time conditions for pet care
5. emotional_sensitivity â€” depth and expressiveness of emotional connection
6. behavioral_consistency â€” alignment between expressed values and actual behavioral intention

Return **only JSON** in this exact format:
{{
ë°˜ë ¤ë™ë¬¼ ê´€ë ¨ ì •ë¶€ì˜ ì¤‘ìš” ì—­í• 

}}
All scores MUST be integers between 0 and 10 inclusive.
""".strip()
    return prompt


# ------------------------------------------------------------
# 5ï¸âƒ£ GPT í˜¸ì¶œ í•¨ìˆ˜ (ì•ˆì •í˜• + 0~10 ì ìˆ˜ ì œí•œ)
# ------------------------------------------------------------
def get_multilabel(row_dict):
    """GPT-4o-miniì— í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ê³  JSON ì‘ë‹µ íŒŒì‹±"""
    prompt = build_prompt(row_dict)

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "You are an expert evaluator."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
            max_tokens=700,
        )

        content = response.choices[0].message.content.strip()
        if not content or len(content) < 5:
            print("âš ï¸ Empty or invalid GPT response.")
            return None

        parsed = safe_parse_json(content)
        if parsed is None:
            print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. GPT ì‘ë‹µ ì¼ë¶€:")
            print(content[:300])
            return None

        # âœ… ì ìˆ˜ í´ë¨í•‘ (0~10 ì •ìˆ˜)
        score_keys = [
            "empathy", "ethicality", "self_control",
            "care_environment", "emotional_sensitivity", "behavioral_consistency"
        ]
        for k in score_keys:
            if k in parsed:
                try:
                    v = round(float(parsed[k]))
                    parsed[k] = int(max(0, min(10, v)))
                except:
                    parsed[k] = None

        return parsed

    except Exception as e:
        print("âš ï¸ API Error:", e)
        return None


# ------------------------------------------------------------
# 6ï¸âƒ£ ì „ì²´ ì‘ë‹µ ë°˜ë³µ ì²˜ë¦¬ + ê²°ê³¼ ì €ì¥
# ------------------------------------------------------------
results = []
# âœ… df_textì˜ ì• 3ê°œ í–‰ë§Œ ìƒ˜í”Œë¡œ ì„ íƒ
sample_df = df_text

for i, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc="Generating Weak Labels"):
    parsed = get_multilabel(row.to_dict())
    if parsed:
        parsed["index"] = i
        results.append(parsed)
    else:
        print(f"âš ï¸ Row {i}: LLM ì‘ë‹µ ì—†ìŒ")

# ê²°ê³¼ ì €ì¥
df_result = pd.DataFrame(results)
os.makedirs(DATA_DIR, exist_ok=True)
save_path = OUTPUT_PATH.replace(".csv", ".xlsx")
df_result.to_excel(save_path, index=False)

print(f"\nğŸ¯ Weak multidimensional labels saved â†’ {save_path}")
print(f"ğŸ§¾ ì´ ìƒì„±ëœ ê²°ê³¼ ìˆ˜: {len(df_result)}")
