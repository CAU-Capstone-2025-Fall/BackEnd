# ============================================================
# ğŸ§© Multidimensional Weak Label ìƒì„± (gpt-4o-mini, 'ë¶„ë¥˜' ë²„ì „)
# ============================================================

import json
import os
import re

import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI
from tqdm import tqdm

# ------------------------------------------------------------
# âœ… í™˜ê²½ ì„¤ì •
# ------------------------------------------------------------
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

DATA_DIR = "../data"
FILE_PATH = os.path.join(DATA_DIR, "survey.xlsx")

# âœ… [ìˆ˜ì •] 0-10ì ìˆ˜(v3)ì™€ êµ¬ë¶„ì„ ìœ„í•´ ìƒˆ ì¶œë ¥ íŒŒì¼ëª… ì§€ì •
OUTPUT_PATH = os.path.join(DATA_DIR, "weak_labels_classification_v1.xlsx")
MODEL_NAME = "gpt-4o-mini"

# ------------------------------------------------------------
# ğŸ§© JSON íŒŒì‹± í•¨ìˆ˜ (ë™ì¼)
# ------------------------------------------------------------
def safe_parse_json(text: str):
    """GPT ì¶œë ¥ì—ì„œ JSON ë¸”ë¡ë§Œ ì¶”ì¶œ í›„ íŒŒì‹±"""
    try:
        match = re.search(r"\{[\s\S]*\}", text)
        if match:
            clean_json = match.group(0)
            return json.loads(clean_json)
        else:
            return json.loads(text.strip())
    except Exception as e:
        print("âš ï¸ JSON Parse Error:", e)
        print("ğŸ§© Raw content (first 300 chars):", text[:300])
        return None


# ------------------------------------------------------------
# 1ï¸âƒ£ ì‹œíŠ¸ ë¡œë“œ (ë™ì¼)
# ------------------------------------------------------------
if not os.path.exists(FILE_PATH):
    raise FileNotFoundError(f"âŒ {FILE_PATH} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

df_raw = pd.read_excel(FILE_PATH, sheet_name="ë§ˆì´í¬ë¡œë°ì´í„°", header=[0, 1])
df_raw.columns = df_raw.columns.get_level_values(1)
df_code = pd.read_excel(FILE_PATH, sheet_name="ì½”ë”©")

print(f"[INFO] ë§ˆì´í¬ë¡œë°ì´í„° shape: {df_raw.shape}")
print(f"[INFO] ì½”ë”© ì‹œíŠ¸ shape: {df_code.shape}")

# ------------------------------------------------------------
# 2ï¸âƒ£ ë§¤í•‘ í…Œì´ë¸” ìƒì„± (ë™ì¼)
# ------------------------------------------------------------
df_code["ANSWER"] = df_code["ANSWER"].astype(str).str.strip()
df_code["VALUE"] = df_code["VALUE"].astype(str).str.strip()
df_code["QUESTION"] = df_code["QUESTION"].astype(str).str.strip()
if "SUB_QUESTION" in df_code.columns:
    df_code["SUB_QUESTION"] = df_code["SUB_QUESTION"].astype(str).str.strip()
else:
    df_code["SUB_QUESTION"] = ""

# (1) VALUE ë§¤í•‘
code_map = {}
for _, row in df_code.dropna(subset=["COLUMNNAME", "ANSWER", "VALUE"]).iterrows():
    col = str(row["COLUMNNAME"]).strip()
    ans = str(row["ANSWER"]).strip()
    val = str(row["VALUE"]).strip()
    code_map[(col, ans)] = val
    try:
        f_ans = str(float(ans))
        code_map[(col, f_ans)] = val
        i_ans = str(int(float(ans)))
        code_map[(col, i_ans)] = val
    except:
        pass

# (2) QUESTION ë§¤í•‘
question_map = {}
for _, row in df_code.dropna(subset=["COLUMNNAME"]).iterrows():
    colname = str(row["COLUMNNAME"]).strip()
    sub_q = str(row.get("SUB_QUESTION", "")).strip()
    main_q = str(row.get("QUESTION", "")).strip()

    if sub_q and sub_q.lower() != "nan":
        question_map[colname] = sub_q
    elif main_q and main_q.lower() != "nan":
        question_map[colname] = main_q

print(f"[INFO] ì½”ë“œ ë§¤í•‘ {len(code_map)}ê°œ, ì§ˆë¬¸ ë§¤í•‘ {len(question_map)}ê°œ ìƒì„± ì™„ë£Œ\n")

# ------------------------------------------------------------
# 3ï¸âƒ£ ì‘ë‹µ ë³µì› (ë™ì¼)
# ------------------------------------------------------------
df_text = pd.DataFrame()

for col in df_raw.columns:
    responses = []
    for _, val in enumerate(df_raw[col]):
        if pd.isna(val):
            responses.append(None)
            continue

        val_str = str(val).strip()
        key = (col, val_str)
        mapped = code_map.get(key)

        if mapped is None:
            try:
                val_float = str(float(val))
                mapped = code_map.get((col, val_float))
            except:
                mapped = None

        responses.append(mapped if mapped is not None else None)

    df_text[col] = responses

print(f"âœ… í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ: {df_text.shape[0]}ê°œ ì‘ë‹µ, {df_text.shape[1]}ê°œ ë¬¸í•­")

# ------------------------------------------------------------
# 4ï¸âƒ£ âœ… [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ ë¹Œë” (0, 1, 2 ìˆ«ì ë¶„ë¥˜ ì‘ì—…)
# ------------------------------------------------------------
def build_prompt(row):
    items = []
    for col, val in row.items():
        if val is None or (isinstance(val, float) and pd.isna(val)):
            continue

        question_text = question_map.get(col, col)
        items.append(f"{question_text}: {val}")

    joined = "\n".join(items)

    # âœ… [ìˆ˜ì •] 0-10ì ìˆ˜(íšŒê·€)ê°€ ì•„ë‹Œ [0, 1, 2](ë¶„ë¥˜)ë¥¼ ìš”ì²­
    prompt = f"""
You are a **strict and critical evaluator** analyzing survey responses about pet ownership.

Below is one respondentâ€™s survey answers.

{joined}

Your task is to **classify this respondent conservatively** across six distinct psychological and behavioral dimensions
related to responsible pet ownership.

Be **objective, analytical, and slightly skeptical**. Avoid giving 'High' (2) ratings unless the evidence in the responses
strongly supports them.

Each dimension must receive one of three integer scores: **[0, 1, 2]**
- 0 = Low (poor or concerning tendencies)
- 1 = Medium (average or mixed tendencies)
- 2 = High (outstanding and clearly justified tendencies)

Dimensions:
1. empathy â€” emotional understanding and compassion toward animals
2. ethicality â€” moral responsibility and respect for animal welfare
3. self_control â€” impulse management and steady caregiving intention
4. care_environment â€” quality of financial, spatial, and time conditions for pet care
5. emotional_sensitivity â€” depth and expressiveness of emotional connection
6. behavioral_consistency â€” alignment between expressed values and actual behavioral intention

Return **only JSON** in this exact format, using **only** the integers 0, 1, or 2:
{{
  "empathy": 1,
  "ethicality": 2,
  "self_control": 0,
  "care_environment": 2,
  "emotional_sensitivity": 1,
  "behavioral_consistency": 1
}}
All values MUST be one of the integers 0, 1, or 2.
""".strip()
    return prompt
# ------------------------------------------------------------
# 5ï¸âƒ£ âœ… [ìˆ˜ì •] GPT í˜¸ì¶œ í•¨ìˆ˜ (0, 1, 2 ìˆ«ì ê²€ì¦)
# ------------------------------------------------------------
def get_multilabel(row_dict):
    """GPT-4o-miniì— í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ê³  JSON ì‘ë‹µ íŒŒì‹±"""
    prompt = build_prompt(row_dict)

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "You are an expert evaluator."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
            max_tokens=700,
        )

        content = response.choices[0].message.content.strip()
        if not content or len(content) < 5:
            print("âš ï¸ Empty or invalid GPT response.")
            return None

        parsed = safe_parse_json(content)
        if parsed is None:
            print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. GPT ì‘ë‹µ ì¼ë¶€:")
            print(content[:300])
            return None

        # ---------------------------------
        # âœ… [ìˆ˜ì •] ë¬¸ìì—´ ê²€ì¦ -> 0, 1, 2 ì •ìˆ˜ ê²€ì¦ ë¡œì§
        # ---------------------------------
        score_keys = [
            "empathy", "ethicality", "self_control",
            "care_environment", "emotional_sensitivity", "behavioral_consistency"
        ]
        valid_scores = {0, 1, 2}

        for k in score_keys:
            if k in parsed:
                try:
                    # GPTê°€ "2", "1.0", 0 ë“± ë¹„í‘œì¤€í™”ëœ ê°’ì„ ì¤˜ë„
                    # ì •ìˆ˜ 0, 1, 2ë¡œ ë³€í™˜
                    v = int(round(float(parsed[k])))
                    
                    if v not in valid_scores:
                        # GPTê°€ ì§€ì‹œë¥¼ ì–´ê¸°ê³  3ì´ë‚˜ -1ì„ ë°˜í™˜í•œ ê²½ìš°
                        print(f"âš ï¸ Invalid score '{v}' for {k}. Defaulting to 1 (Medium).")
                        parsed[k] = 1 # ì•ˆì „í•œ ê¸°ë³¸ê°’ 'Medium'
                    else:
                        parsed[k] = v # 0, 1, 2
                except Exception:
                    # ê·¸ ì™¸ ëª¨ë“  ì—ëŸ¬ (ì˜ˆ: "High" ë¬¸ìì—´, null)
                    parsed[k] = 1 # ì•ˆì „í•œ ê¸°ë³¸ê°’ 'Medium'
            else:
                # í‚¤ê°€ ëˆ„ë½ëœ ê²½ìš°
                parsed[k] = 1
        # ---------------------------------
        # [ìˆ˜ì •] ë
        # ---------------------------------

        return parsed

    except Exception as e:
        print("âš ï¸ API Error:", e)
        return None
# ------------------------------------------------------------
# 6ï¸âƒ£ ì „ì²´ ì‘ë‹µ ë°˜ë³µ ì²˜ë¦¬ + ê²°ê³¼ ì €ì¥ (ë™ì¼)
# ------------------------------------------------------------
results = []
# âœ… df_textì˜ ëª¨ë“  í–‰ì„ ì²˜ë¦¬
sample_df = df_text

for i, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc="Generating Weak Labels (Classification)"):
    parsed = get_multilabel(row.to_dict())
    if parsed:
        parsed["index"] = i
        results.append(parsed)
    else:
        print(f"âš ï¸ Row {i}: LLM ì‘ë‹µ ì—†ìŒ")

# ê²°ê³¼ ì €ì¥
df_result = pd.DataFrame(results)
os.makedirs(DATA_DIR, exist_ok=True)

# âœ… [ìˆ˜ì •] OUTPUT_PATHê°€ ì´ë¯¸ .xlsxë¥¼ ê°€ë¦¬í‚¤ë„ë¡ ìˆ˜ì •
save_path = OUTPUT_PATH 
df_result.to_excel(save_path, index=False)

print(f"\nğŸ¯ Weak classification labels saved â†’ {save_path}")
print(f"ğŸ§¾ ì´ ìƒì„±ëœ ê²°ê³¼ ìˆ˜: {len(df_result)}")