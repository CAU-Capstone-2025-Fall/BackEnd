# ============================================================
# evaluate_regression.py (Y_4labels íšŒê·€ìš© ìµœì¢… í‰ê°€)
# ============================================================

import os
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import torch.nn as nn
import yaml

# âš ï¸ 'models.py'ì™€ 'train_utils.py'ê°€ ì„í¬íŠ¸ ê°€ëŠ¥í•´ì•¼ í•¨
from models import MLP, StudentNet, TeacherNet
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from torch.utils.data import TensorDataset, random_split

# from train_utils import metrics_dict # (metrics_dict ëŒ€ì‹  regression_metrics ì‚¬ìš©)


# ============================================================
# 1ï¸âƒ£ Validation ë³µì› + Label ë§¤ì¹­ (Regression)
# ============================================================
def load_holdout_data(A, B, label_path, val_split=0.2, seed=42):
    A_t = torch.tensor(A, dtype=torch.float32)
    B_t = torch.tensor(B, dtype=torch.float32)

    # â—ï¸ [ìˆ˜ì •] label_pathê°€ Path ê°ì²´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ str() ì²˜ë¦¬
    label_path_str = str(label_path)
    if label_path_str.endswith(".csv"):
        df_label = pd.read_csv(label_path_str)
    else:
        df_label = pd.read_excel(label_path_str)
    
    # Y_4labels.csvì˜ 4ê°œ ì»¬ëŸ¼ (index ì œì™¸)
    feature_cols = [c for c in df_label.columns if c not in ["Unnamed: 0", "index"]]
    print(f"[INFO] Using label columns: {feature_cols}")

    assert len(A_t) == len(df_label), "A/Bì™€ ë¼ë²¨ ë°ì´í„°ì˜ ìƒ˜í”Œ ìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤."
    
    # â—ï¸ [ìˆ˜ì •] Y_t(ë ˆì´ë¸”)ë¥¼ 'float' íƒ€ì…ìœ¼ë¡œ ë¡œë“œ (íšŒê·€)
    Y_t = torch.tensor(df_label[feature_cols].values, dtype=torch.float32)
    ds = TensorDataset(A_t, B_t, Y_t)

    n_val = int(len(ds) * val_split)
    n_train = len(ds) - n_val
    gen = torch.Generator().manual_seed(seed)
    tr_ds, va_ds = random_split(ds, [n_train, n_val], generator=gen)

    # í›ˆë ¨ ì…‹ (A_tr, B_tr, Y_tr)
    A_tr = torch.stack([s[0] for s in tr_ds])
    B_tr = torch.stack([s[1] for s in tr_ds])
    Y_tr = torch.stack([s[2] for s in tr_ds]) # (float íƒ€ì…)

    # ê²€ì¦ ì…‹ (A_val, B_val, Y_val)
    A_val = torch.stack([s[0] for s in va_ds])
    B_val = torch.stack([s[1] for s in va_ds])
    Y_val = torch.stack([s[2] for s in va_ds]) # (float íƒ€ì…)

    print(f"[LOAD] Train set: {len(A_tr)}, Validation set: {len(A_val)}")
    return A_tr, B_tr, Y_tr, A_val, B_val, Y_val, feature_cols


# ============================================================
# 2ï¸âƒ£ Baseline (A only) (Regression)
# ============================================================
class BaselineNet(nn.Module):
    # â—ï¸ [ìˆ˜ì •] 'ë¶„ë¥˜'ìš© num_classes ì¸ì ì œê±°
    def __init__(self, dim_A, dim_y, enc_hidden, clf_hidden, z_dim, 
                 p_drop=0.1, use_layernorm=False):
        super().__init__()
        self.encoder = MLP(dim_A, z_dim, enc_hidden, p_drop, use_layernorm)
        # â—ï¸ [ìˆ˜ì •] 'ë¶„ë¥˜ê¸°'ê°€ ì•„ë‹Œ 'íšŒê·€(Regressor)'
        self.regressor = MLP(z_dim, dim_y, clf_hidden, p_drop, use_layernorm)

    def forward(self, x):
        z = self.encoder(x)
        y = self.regressor(z) # (Batch, 4) ì˜ˆì¸¡ê°’ ë°˜í™˜
        return y, z


# ============================================================
# 3ï¸âƒ£ Metrics (Regression)
# ============================================================
def regression_metrics(y_true, y_pred):
    y_true_np = y_true.detach().cpu().numpy()
    y_pred_np = y_pred.detach().cpu().numpy()
    
    mse = mean_squared_error(y_true_np, y_pred_np)
    mae = mean_absolute_error(y_true_np, y_pred_np)
    rmse = np.sqrt(mse)
    # â—ï¸ [ìˆ˜ì •] R2ëŠ” multi-output='variance_weighted' (í‘œì¤€) ë˜ëŠ” 'uniform_average'
    r2 = r2_score(y_true_np, y_pred_np, multioutput='variance_weighted') 
    
    # 4ê°œ ë ˆì´ë¸” ê°ê°ì˜ R2ë„ ê³„ì‚°
    r2_per_dim = r2_score(y_true_np, y_pred_np, multioutput='raw_values')
    
    metrics = {"MSE": mse, "MAE": mae, "RMSE": rmse, "R2": r2}
    # 4ê°œ íŠ¹ì„± R2 ì¶”ê°€ (ì˜ˆ: R2_attitude)
    for i, col in enumerate(FEATURE_COLS):
        metrics[f"R2_{col}"] = r2_per_dim[i]
        
    return metrics


# ============================================================
# 4ï¸âƒ£ ëª¨ë¸ í‰ê°€ ë£¨í‹´ (Regression)
# ============================================================
def evaluate_models(
    A_tr, B_tr, Y_tr,
    A_val, B_val, Y_val,
    TeacherNet, StudentNet,
    teacher_ckpt, student_ckpt,
    teacher_model_cfg, student_model_cfg,
    device='cuda', out_dir="./eval_results"
):
    os.makedirs(out_dir, exist_ok=True)
    A_tr, Y_tr = A_tr.to(device), Y_tr.to(device, dtype=torch.float32)
    A_val, B_val, Y_val = A_val.to(device), B_val.to(device), Y_val.to(device, dtype=torch.float32)
    
    mse_loss = nn.MSELoss() # â—ï¸ Baseline í›ˆë ¨ìš©

    # --- 1. Teacher
    with torch.no_grad():
        # â—ï¸ [ìˆ˜ì •] num_classes ì œê±° (íšŒê·€ ëª¨ë¸ __init__ ê°€ì •)
        teacher = TeacherNet(
            dim_A=teacher_model_cfg["dim_A"],
            dim_B=teacher_model_cfg["dim_B"],
            dim_y=teacher_model_cfg["dim_y"],
            encA_hidden=teacher_model_cfg["encA_hidden"],
            encB_hidden=teacher_model_cfg["encB_hidden"],
            clf_hidden=teacher_model_cfg["clf_hidden"],
            z_dim_A=teacher_model_cfg["z_dim_A"],
            z_dim_B=teacher_model_cfg["z_dim_B"],
            p_drop=teacher_model_cfg["p_drop"],
            use_layernorm=teacher_model_cfg["use_layernorm"]
        ).to(device)
        teacher.load_state_dict(torch.load(teacher_ckpt, map_location=device, weights_only=True))
        teacher.eval()
        Yp_teacher, _, _ = teacher(A_val, B_val) # (B, 4)
        metrics_teacher = regression_metrics(Y_val, Yp_teacher)

    # --- 2. Student
    with torch.no_grad():
        student = StudentNet(
            dim_A=student_model_cfg["dim_A"],
            dim_y=student_model_cfg["dim_y"],
            enc_hidden=student_model_cfg["enc_hidden"],
            clf_hidden=student_model_cfg["clf_hidden"],
            z_dim=student_model_cfg["z_dim"],
            p_drop=student_model_cfg["p_drop"],
            use_layernorm=student_model_cfg["use_layernorm"]
        ).to(device)
        student.load_state_dict(torch.load(student_ckpt, map_location=device, weights_only=True))
        student.eval()
        Yp_student, _ = student(A_val) # (B, 4)
        metrics_student = regression_metrics(Y_val, Yp_student)

    # --- 3. Baseline
    baseline = BaselineNet(
        dim_A=student_model_cfg["dim_A"],
        dim_y=student_model_cfg["dim_y"],
        enc_hidden=student_model_cfg["enc_hidden"],
        clf_hidden=student_model_cfg["clf_hidden"],
        z_dim=student_model_cfg["z_dim"],
        p_drop=student_model_cfg["p_drop"],
        use_layernorm=student_model_cfg["use_layernorm"]
    ).to(device)

    opt = torch.optim.AdamW(baseline.parameters(), lr=1e-3, weight_decay=1e-4)
    epochs = 50 

    for ep in range(epochs):
        baseline.train()
        opt.zero_grad()
        y_pred, _ = baseline(A_tr)
        loss = mse_loss(y_pred, Y_tr) # â—ï¸ [ìˆ˜ì •] íšŒê·€ìš© MSELoss
        loss.backward()
        opt.step()

    with torch.no_grad():
        baseline.eval()
        Yp_base, _ = baseline(A_val) # (B, 4)
        metrics_base = regression_metrics(Y_val, Yp_base)

    # --- 4. ê²°ê³¼ ìš”ì•½
    df = pd.DataFrame([
        {"Model": "Teacher (A+B)", **metrics_teacher},
        {"Model": "Student (Distilled)", **metrics_student},
        {"Model": "Baseline (A only)", **metrics_base},
    ])
    df_rounded = df.round(4)
    df.to_csv(os.path.join(out_dir, "eval_summary.csv"), index=False)
    print("\n===== ğŸ“Š Evaluation Summary =====")
    print(df_rounded)

    # --- 5. ì‹œê°í™” (íšŒê·€ìš©)
    # â—ï¸ [ìˆ˜ì •] R2, MSE ë“± íšŒê·€ ì§€í‘œ
    metrics_to_plot = ["R2", "MSE", "MAE"]
    palette = ["#ff7f0e", "#1f77b4", "#2ca02c"]
    n_metrics = len(metrics_to_plot)

    plt.figure(figsize=(max(5, n_metrics * 3), 5))
    for i, metric in enumerate(metrics_to_plot):
        plt.subplot(1, n_metrics, i + 1)
        sns.barplot(x="Model", y=metric, hue="Model", data=df, palette=palette, legend=False, order=df['Model'])
        plt.title(metric)
        plt.xticks(rotation=25, ha='right')
        if metric == "R2":
            plt.axhline(0, color='black', linestyle='--', lw=1) # R2=0 ê¸°ì¤€ì„ 
            
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    plt.suptitle("Model Performance on Hold-out Validation Set")
    plt.savefig(os.path.join(out_dir, "eval_barplots.png"), dpi=200)
    plt.close()

    # â—ï¸ [ì‚­ì œ] Scatter Plotì€ 4Dë¼ì„œ mean() ë¹„êµëŠ” ë¬´ì˜ë¯¸
    
    # --- 6. ì˜ˆì¸¡ê°’ ì €ì¥
    df_pred_true = pd.DataFrame(Y_val.cpu().numpy(), columns=FEATURE_COLS)
    df_pred_teacher = pd.DataFrame(Yp_teacher.cpu().numpy(), columns=[f"pred_T_{c}" for c in FEATURE_COLS])
    df_pred_student = pd.DataFrame(Yp_student.cpu().numpy(), columns=[f"pred_S_{c}" for c in FEATURE_COLS])
    df_pred_baseline = pd.DataFrame(Yp_base.cpu().numpy(), columns=[f"pred_B_{c}" for c in FEATURE_COLS])
    
    df_pred_all = pd.concat([df_pred_true, df_pred_teacher, df_pred_student, df_pred_baseline], axis=1)
    df_pred_all.to_csv(os.path.join(out_dir, "val_predictions_regression.csv"), index=False)
    
    print(f"[SAVE] All results saved â†’ {out_dir}")

    return df


# ============================================================
# 5ï¸âƒ£ ì‹¤í–‰ ì˜ˆì‹œ
# ============================================================
if __name__ == "__main__":
    BASE_DIR = Path(__file__).resolve().parent
    DATA_DIR = BASE_DIR.parent / "data"
    CKPT_DIR = BASE_DIR / "checkpoints"
    OUT_DIR = BASE_DIR / "eval_results"

    CONFIG_PATH = BASE_DIR / "config.yaml"
    with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
        cfg = yaml.safe_load(f)
    print("[LOAD] config.yaml loaded.")

    # --- [ìˆ˜ì •] A_noex, B_clean ë¡œë“œ
    try:
        A = pd.read_csv(DATA_DIR / "A_noex.csv").to_numpy()
        B = pd.read_csv(DATA_DIR / "B_clean.csv").to_numpy()
    except FileNotFoundError:
        print(f"A_noex.csv/B_clean.csv not found, trying .npy")
        A = np.load(DATA_DIR / "A.npy")
        B = np.load(DATA_DIR / "B_clean.csv.npy") # B_clean.npy?

    # --- [ìˆ˜ì •] Y_4labels.csv ë¡œë“œ
    label_path = DATA_DIR / "label" / "Y_4labels.csv"
    if not label_path.exists():
        # Fallback (Y_candidatesì—ì„œ ì°¾ê¸°)
        print(f"Warning: {label_path} not found. Searching in config.filenames.Y_candidates...")
        Y_candidates = cfg['filenames']['Y_candidates']
        search_dirs = [DATA_DIR, DATA_DIR / "label", BASE_DIR.parent]
        for sdir in search_dirs:
            for cand in Y_candidates:
                p = sdir / (cand + ".csv")
                if p.exists(): label_path = p; break
            if label_path: break
        if not label_path:
            raise FileNotFoundError(f"Could not find Y_4labels.csv or candidates in {search_dirs}")

    print(f"[LOAD] Using Label file: {label_path}")

    # â—ï¸ [ìˆ˜ì •] FEATURE_COLSë¥¼ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ê¸° ìœ„í•´ ë¡œë“œ
    A_tr, B_tr, Y_tr, A_val, B_val, Y_val, loaded_feature_cols = load_holdout_data(
        A, B, label_path, 
        val_split=cfg['teacher_train']['val_split'], 
        seed=cfg['seed']
    )
    FEATURE_COLS = loaded_feature_cols # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
    true_dim_y = Y_val.shape[1] # 4

    # --- config ë”•ì…”ë„ˆë¦¬ì— dim ì •ë³´ ì£¼ì…
    # â—ï¸ [ìˆ˜ì •] 'num_classes' í‚¤ ì œê±° (íšŒê·€)
    cfg['teacher_model'].update({
        "dim_A": A.shape[1],
        "dim_B": B.shape[1],
        "dim_y": true_dim_y,
    })
    cfg['student_model'].update({
        "dim_A": A.shape[1],
        "dim_y": true_dim_y,
    })
    cfg['teacher_model'].pop('num_classes', None)
    cfg['student_model'].pop('num_classes', None)
    
    # (use_layernorm ë™ê¸°í™”)
    if 'use_layernorm' not in cfg['teacher_model']:
         cfg['teacher_model']['use_layernorm'] = False
    if 'use_layernorm' not in cfg['student_model']:
         cfg['student_model']['use_layernorm'] = False

    # --- [ìˆ˜ì •] ì²´í¬í¬ì¸íŠ¸ ì´ë¦„
    teacher_ckpt = CKPT_DIR / "teacher.pt" # â—ï¸ (Optuna/configì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸)
    student_ckpt = CKPT_DIR / "student.pt"

    device = "cuda" if torch.cuda.is_available() else "cpu"

    evaluate_models(
        A_tr, B_tr, Y_tr,
        A_val, B_val, Y_val,
        TeacherNet, StudentNet,
        teacher_ckpt, student_ckpt,
        teacher_model_cfg=cfg['teacher_model'],
        student_model_cfg=cfg['student_model'],
        device=device, out_dir=OUT_DIR
    )