# ============================================================
# run_distill.py â€” (íšŒê·€: Y_4labels) Teacherâ€“Student Distillation
# ============================================================

import os
from pathlib import Path

import numpy as np
import torch
import yaml
from dataio import load_config, load_inputs_and_labels, resolve_device
from models import StudentNet, TeacherNet
from trainer import train_student_distill, train_teacher


def main():
    base = Path(__file__).resolve().parent

    # â”€â”€ 1) ì„¤ì • ë¡œë“œ
    cfg_path = base / "config.yaml"
    if cfg_path.exists():
        cfg = load_config(str(cfg_path))
    else:
        with open(cfg_path, encoding="utf-8") as f:
            cfg = yaml.safe_load(f)

    DEVICE = resolve_device(cfg.get("device", "auto"))
    torch.set_float32_matmul_precision("medium")

    # â”€â”€ 2) ë°ì´í„° ë¡œë“œ (A_noex, B_clean, Y_4labels)
    A, B, Y = load_inputs_and_labels(cfg)
    print(f"âœ… [LOAD COMPLETE] Shapes â†’ A={np.shape(A)}, B={np.shape(B)}, Y={np.shape(Y)}")

    # Convert to tensors
    A = torch.tensor(A, dtype=torch.float32, device=DEVICE)
    B = torch.tensor(B, dtype=torch.float32, device=DEVICE)
    
    # â—ï¸ [ìˆ˜ì •] Yë¥¼ 'float' (íšŒê·€) íƒ€ì…ìœ¼ë¡œ ë¡œë“œ
    Y = torch.tensor(Y, dtype=torch.float32, device=DEVICE) 

    # â—ï¸ [ìˆ˜ì •] dim_yëŠ” Yì˜ ì»¬ëŸ¼ ìˆ˜ (ì˜ˆ: 4)
    if Y.ndim == 1:
        Y = Y.unsqueeze(1) # (N,) -> (N, 1)
    dim_y = Y.shape[1] 
    print(f"âœ… [INFO] Target dim_y = {dim_y}")

    # â”€â”€ 3) ëª¨ë¸/í•™ìŠµ ì„¤ì • êµ¬ì„± (íšŒê·€ìš©)
    # â—ï¸ [ìˆ˜ì •] 'num_classes' í‚¤ ì œê±°
    teacher_model_cfg = {
        "z_dim_A": cfg["teacher_model"]["z_dim_A"],
        "z_dim_B": cfg["teacher_model"]["z_dim_B"],
        "encA_hidden": tuple(cfg["teacher_model"]["encA_hidden"]),
        "encB_hidden": tuple(cfg["teacher_model"]["encB_hidden"]),
        "clf_hidden": tuple(cfg["teacher_model"]["clf_hidden"]),
        "p_drop": cfg["teacher_model"]["p_drop"],
        "use_layernorm": cfg["teacher_model"].get("use_layernorm", False),
        "dim_A": A.shape[1], # â—ï¸ (ì¶”ê°€) models.pyê°€ í•„ìš”ë¡œ í•  ê²½ìš° ëŒ€ë¹„
        "dim_B": B.shape[1], # â—ï¸ (ì¶”ê°€)
        "dim_y": dim_y,      # â—ï¸ (ì¶”ê°€)
    }

    student_model_cfg = {
        "z_dim": cfg["student_model"]["z_dim"],
        "enc_hidden": tuple(cfg["student_model"]["enc_hidden"]),
        "clf_hidden": tuple(cfg["student_model"]["clf_hidden"]),
        "p_drop": cfg["student_model"]["p_drop"],
        "use_layernorm": cfg["student_model"].get("use_layernorm", False),
        "dim_A": A.shape[1], # â—ï¸ (ì¶”ê°€)
        "dim_y": dim_y,      # â—ï¸ (ì¶”ê°€)
    }
    
    # â—ï¸ (ì¤‘ìš”) 'num_classes'ê°€ config.yamlì— ìˆì–´ë„ ë¬´ì‹œí•˜ê³  ëª¨ë¸ì— ì•ˆ ë„˜ê¹€
    teacher_model_cfg.pop("num_classes", None)
    student_model_cfg.pop("num_classes", None)


    teacher_train_cfg = {**cfg["teacher_train"], "device": DEVICE}
    student_train_cfg = {**cfg["student_train"], "device": DEVICE}

    # â”€â”€ 4) Teacher í•™ìŠµ
    print("\nğŸš€ Training Teacher Network (Regression)...")
    teacher, teacher_hist = train_teacher(
        A, B, Y, dim_y,
        model_cfg=teacher_model_cfg,
        train_cfg=teacher_train_cfg,
        TeacherNet=TeacherNet,
        loss_weights=cfg.get("loss_weights", {})
    )

    # â”€â”€ 5) Student(KD) í•™ìŠµ
    print("\nğŸ“ Training Student Network with KD (Regression)...")
    student, student_hist = train_student_distill(
        A, B, Y,
        teacher=teacher,
        dim_y=dim_y,
        model_cfg=student_model_cfg,
        train_cfg=student_train_cfg,
        StudentNet=StudentNet,
        kd_cfg=cfg.get("student_kd", {}),
        init_from_teacher=True
    )

    # â”€â”€ 6) ë¯¸ë¦¬ë³´ê¸° (StudentëŠ” Aë§Œ ì…ë ¥ë°›ìŒ)
    preview_rows = int(cfg.get("inference", {}).get("preview_rows", 5))
    preview_rows = min(preview_rows, A.shape[0])

    student.eval()
    with torch.no_grad():
        A_preview = A[:preview_rows].to(DEVICE, dtype=torch.float32)
        out = student(A_preview)
        preds = out[0] if isinstance(out, tuple) else out
        preds_np = preds.detach().cpu().numpy()

    print("\n[Preview Predictions (Regression)]")
    print(preds_np)

    # â”€â”€ 7) Teacher latent í’ˆì§ˆ ë¶„ì„ ë° Tâ€“S ì •ë ¬ í‰ê°€
    try:
        from evaluation_utils import (
            evaluate_teacher_latent,
            plot_teacher_student_alignment,
        )
        
        os.makedirs(base / "analysis_results", exist_ok=True)
        analysis_dir = os.path.join(base, "analysis_results")

        print("\n[Auto-Eval] Running Teacher latent quality analysis...")
        evaluate_teacher_latent(
            teacher, A.cpu().numpy(), B.cpu().numpy(),
            save_dir=analysis_dir
        )

        print("\n[Auto-Eval] Running Teacherâ€“Student alignment analysis...")
        plot_teacher_student_alignment(
            teacher, student,
            A.cpu().numpy(), B.cpu().numpy(),
            save_dir=analysis_dir
        )
    except ImportError:
        print("\n[WARN] 'evaluation_utils' not found. Skipping auto-evaluation.")
    except Exception as e:
        print(f"[WARN] Auto-evaluation skipped: {e}")

    # â”€â”€ 8) ì €ì¥ ìœ„ì¹˜ ì•ˆë‚´
    print("\nâœ… All training completed successfully.")
    # â—ï¸ (ìˆ˜ì •) config.yamlì—ì„œ ì‹¤ì œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ëª… ì°¸ì¡°
    teacher_ckpt_name = cfg["teacher_train"].get("ckpt_name", "teacher.pt")
    student_ckpt_name = cfg["student_train"].get("ckpt_name", "student.pt")
    
    print(f"   â”œâ”€ Teacher checkpoint: {teacher_train_cfg['ckpt_dir']}/{teacher_ckpt_name}")
    print(f"   â””â”€ Student checkpoint: {student_train_cfg['ckpt_dir']}/{student_ckpt_name}")


if __name__ == "__main__":
    main()