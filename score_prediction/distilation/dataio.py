# =========================================
# dataio.py â€” Unified (label_dir ê¸°ë°˜, Fully Stabilized)
# =========================================
import os
from pathlib import Path

import numpy as np
import pandas as pd
import torch
import yaml
from sklearn.preprocessing import StandardScaler


# ------------------------------------------------
# 1ï¸âƒ£ Config & Device Utility
# ------------------------------------------------
def load_config(path):
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def resolve_device(device_str="auto"):
    if device_str == "auto":
        return "cuda" if torch.cuda.is_available() else "cpu"
    return device_str


# ------------------------------------------------
# 2ï¸âƒ£ Universal Table Loader
# ------------------------------------------------
def _read_any_table(path, excel_sheet=None, excel_header=0, select_numeric_only=True, fill_nan_value=0.0):
    """ì—‘ì…€/CSV/NPY íŒŒì¼ì„ ìë™ ì¸ì‹í•´ DataFrameìœ¼ë¡œ ë¡œë“œ"""
    ext = os.path.splitext(path)[1].lower()

    if ext == ".npy":
        arr = np.load(path)
        if arr.ndim == 1:
            arr = arr.reshape(-1, 1)
        return pd.DataFrame(arr)

    elif ext in [".xlsx", ".xls"]:
        df = pd.read_excel(path, sheet_name=excel_sheet, header=excel_header)
        if isinstance(df, dict):  # ë‹¤ì¤‘ì‹œíŠ¸ ëŒ€ì‘
            df = list(df.values())[0]
    else:
        df = pd.read_csv(path, header=excel_header)

    # ìˆ«ìí˜• ë³€í™˜ ì‹œë„
    for c in df.columns:
        df[c] = pd.to_numeric(df[c], errors="ignore")

    # ì„ íƒì ìœ¼ë¡œ ìˆ«ìí˜•ë§Œ ìœ ì§€
    if select_numeric_only and df.select_dtypes(include=["number"]).shape[1] > 0:
        df = df.select_dtypes(include=["number"])

    # ê²°ì¸¡ì¹˜ ì±„ì›€
    df = df.fillna(fill_nan_value)

    return df


# ------------------------------------------------
# 3ï¸âƒ£ File Finder
# ------------------------------------------------
def _find_existing_file(base_dir, candidates):
    """í›„ë³´ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ ì¤‘ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    base_dir = Path(base_dir)
    for root, _, files in os.walk(base_dir):
        for name in candidates:
            for ext in [".csv", ".xlsx", ".xls", ".npy"]:
                if f"{name}{ext}" in files:
                    return str(Path(root) / f"{name}{ext}")
    raise FileNotFoundError(f"None of {candidates} found under {base_dir}")


# ------------------------------------------------
# 4ï¸âƒ£ Info Printer
# ------------------------------------------------
def _print_feature_info(df, name):
    print(f"\nğŸ“Š [{name}] Feature Summary")
    print(f"  â€¢ ì´ ìƒ˜í”Œ ìˆ˜: {len(df):,}")
    print(f"  â€¢ í”¼ì²˜ ê°œìˆ˜: {df.shape[1]}")
    print(f"  â€¢ ê²°ì¸¡ì¹˜ í‰ê·  ê°œìˆ˜: {df.isna().sum().mean():.1f}")
    print(f"  â€¢ í”¼ì²˜ ëª©ë¡: {list(df.columns[:8])}{' ...' if len(df.columns) > 8 else ''}")
    if len(df) > 0:
        print(f"  â€¢ ì˜ˆì‹œ 1í–‰: {df.iloc[0].to_dict()}")
    else:
        print("  â€¢ ì˜ˆì‹œ 1í–‰: N/A")


# ------------------------------------------------
# 5ï¸âƒ£ Main Loader
# ------------------------------------------------
def load_inputs_and_labels(cfg):
    """A,B,Y ìë™ íƒìƒ‰ ë° ì „ì²˜ë¦¬"""
    base_dir = Path(os.path.dirname(__file__)) / cfg["paths"]["data_dir"]
    label_dir = Path(cfg["paths"].get("label_dir", base_dir))  # âœ… label_dirë§Œ ì‚¬ìš©
    fn_cfg = cfg["filenames"]
    excel_cfg = cfg.get("excel", {})
    prep_cfg = cfg.get("preprocess", {})

    # -------------------------------
    # íŒŒì¼ íƒìƒ‰
    # -------------------------------
    A_path = _find_existing_file(base_dir, fn_cfg["A_candidates"])
    B_path = _find_existing_file(base_dir, fn_cfg["B_candidates"])
    Y_path = _find_existing_file(label_dir, fn_cfg["Y_candidates"])

    print("[load_inputs_and_labels] Found files:")
    print(f"  A â†’ {os.path.basename(A_path)}")
    print(f"  B â†’ {os.path.basename(B_path)}")
    print(f"  Y â†’ {os.path.basename(Y_path)}")

    # -------------------------------
    # íŒŒì¼ ë¡œë“œ
    # -------------------------------
    A_df = _read_any_table(
        A_path,
        excel_sheet=excel_cfg.get("sheet_A"),
        excel_header=excel_cfg.get("header", 0),
        select_numeric_only=True,
        fill_nan_value=prep_cfg.get("fill_nan_value", 0.0),
    )

    B_df = _read_any_table(
        B_path,
        excel_sheet=excel_cfg.get("sheet_B"),
        excel_header=excel_cfg.get("header", 0),
        select_numeric_only=True,
        fill_nan_value=prep_cfg.get("fill_nan_value", 0.0),
    )

    Y_df = _read_any_table(
        Y_path,
        excel_sheet=excel_cfg.get("sheet_Y"),
        excel_header=excel_cfg.get("header", 0),
        select_numeric_only=False,  # âœ… YëŠ” ë°˜ë“œì‹œ ì „ì²´ ì»¬ëŸ¼ ìœ ì§€
        fill_nan_value=prep_cfg.get("fill_nan_value", 0.0),
    )

    # -------------------------------
    # ë¼ë²¨ í•„í„°ë§
    # -------------------------------
    expected_cols = ["attitude", "civic", "burden", "behavior"]
    valid_cols = [c for c in expected_cols if c in Y_df.columns]

    if len(valid_cols) == 0:
        print("âš ï¸ [WARNING] No valid Y columns found in label file.")
        print(f"    Available columns: {list(Y_df.columns)}")
        Y_df = pd.DataFrame(np.zeros((len(A_df), 1)), columns=["dummy"])
    else:
        dropped = [c for c in Y_df.columns if c not in valid_cols]
        if dropped:
            print(f"[WARN] Extra columns dropped from Y: {dropped}")
        Y_df = Y_df[valid_cols]

    # -------------------------------
    # ì •ë³´ ì¶œë ¥
    # -------------------------------
    _print_feature_info(A_df, "A (Quantitative)")
    _print_feature_info(B_df, "B (Qualitative)")
    _print_feature_info(Y_df, "Y (Label)")

    # -------------------------------
    # NumPy ë³€í™˜ + Scaling
    # -------------------------------
    A = StandardScaler().fit_transform(A_df.to_numpy(dtype=np.float32))
    B = StandardScaler().fit_transform(B_df.to_numpy(dtype=np.float32))
    Y = Y_df.to_numpy(dtype=np.float32)

    # -------------------------------
    # Shape ê²€ì¦
    # -------------------------------
    if not (len(A) == len(B) == len(Y)):
        raise ValueError(f"âŒ Size mismatch among A,B,Y â†’ A={A.shape}, B={B.shape}, Y={Y.shape}")

    print(f"\nâœ… [LOAD COMPLETE] Shapes â†’  A={A.shape}, B={B.shape}, Y={Y.shape}")
    return A, B, Y
